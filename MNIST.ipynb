{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhes23/deep_learning/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKJei9hr3MlP"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from enum import Enum\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_H7qxjT2_r8"
      },
      "source": [
        "# Importing and plotting samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjBCjYrvwVre"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "QKKTyjeynEAH",
        "outputId": "fa79d34c-9642-4763-a6b8-882d913ee1e9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2016x2016 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "no_of_items = 10\n",
        "\n",
        "fig, axes = plt.subplots(nrows = 1, ncols=10, figsize = (28, 28))\n",
        "for item in range(no_of_items):\n",
        "  index = 0\n",
        "  while(y_train[index] != item): #searching for the first occurance of the element\n",
        "    index = index+1\n",
        "  \n",
        "  ax = axes[item]\n",
        "  ax.imshow(x_train[index], cmap='gray_r')\n",
        "  ax.set_title('Label {}'.format(item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfO1a_Bl3F7U"
      },
      "source": [
        "# Reshaping the data for nerual network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX-O8TPP3FTm"
      },
      "outputs": [],
      "source": [
        "no_of_pixels = x_train[0].size\n",
        "x_train = x_train.reshape(-1, no_of_pixels)/255\n",
        "x_test = x_test.reshape(-1, no_of_pixels)/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCrUeXGzewLj"
      },
      "source": [
        "# Some Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMEmeqnafDw5"
      },
      "outputs": [],
      "source": [
        "class ActivationFunction(Enum):\n",
        "  SIGMOID = 1\n",
        "  RELU = 2\n",
        "  TAN_H = 3\n",
        "\n",
        "class InitializationMethod(Enum):\n",
        "  UNIFORM_RANDOM = 1\n",
        "  UNIFORM_XAVIER = 2\n",
        "  GAUSSIAN_XAVIER = 3\n",
        "\n",
        "class OutputFunction(Enum):\n",
        "  SOFTMAX = 1\n",
        "  SQUARE_ERROR = 2\n",
        "\n",
        "class OptimizationAlgorithm(Enum):\n",
        "  GD = 1\n",
        "  SGD = 2\n",
        "  MINI_BATCH = 3\n",
        "  MOMENTUM_GD = 4\n",
        "  NAG = 5\n",
        "  RMS_PROP = 6\n",
        "  ADAM = 7\n",
        "  NADAM = 8\n",
        "\n",
        "class ErrorCalculationMethod(Enum):\n",
        "  CROSS_ENTROPY = 1\n",
        "  MEAN_SQUARE_ERROR = 2\n",
        "\n",
        "def calc_accuracy(predicted, expected):\n",
        "  \"\"\"Takes predicted values and expcted values, and return the accuracy (in the range of 0 to 1)\n",
        "  \n",
        "  Parameters:\n",
        "  ----------\n",
        "  predicted: ndarray\n",
        "    predicted values\n",
        "  expected: ndarray\n",
        "    expected values\n",
        "  \"\"\"\n",
        "  return np.sum(predicted == expected) / expected.size\n",
        "\n",
        "\n",
        "def activation_function(a, func):\n",
        "  \"\"\"\n",
        "  Calculates post activation values from pre-activation values, functions implemented:\n",
        "  * Sigmoid\n",
        "  * ReLU\n",
        "  * Tan h\n",
        "\n",
        "  Parameters:\n",
        "  -----------\n",
        "  a: ndarray, pre-activation values\n",
        "  func: Enum describing the activation function type\n",
        "\n",
        "  Retruns:\n",
        "  -------\n",
        "  Post activation values in ndarray of the same dimention\n",
        "  \"\"\"\n",
        "  if(func == ActivationFunction.SIGMOID):   \n",
        "    # clipping_limit = 400\n",
        "    # return 1.0 / (1.0 + np.exp(-np.clip(a,-clipping_limit,clipping_limit)))\n",
        "    new = a.copy()\n",
        "    new[a<0] = np.exp(a[a<0])/(1.0 + np.exp(a[a<0]))\n",
        "    new[a>=0] = 1/(1+np.exp(-a[a>=0]))\n",
        "    return new\n",
        "\n",
        "  if(func == ActivationFunction.RELU):\n",
        "    return np.maximum(0,a)\n",
        "\n",
        "  if(func == ActivationFunction.TAN_H):\n",
        "    e_pow_a = np.exp(a)\n",
        "    e_pow_neg_a = np.exp(-a)\n",
        "    return (e_pow_a - e_pow_neg_a)/(e_pow_a + e_pow_neg_a)\n",
        "\n",
        "\n",
        "def df_activation_function(a, func):\n",
        "  \"\"\"\n",
        "  Calculates the derivative of the activation function\n",
        "  \n",
        "  Parameters:\n",
        "  -------\n",
        "  a: ndarray, pre-activation values\n",
        "  func: Enum describing the activation function type\n",
        "  \n",
        "  \"\"\"\n",
        "  if(func == ActivationFunction.SIGMOID): \n",
        "    return activation_function(a, func) * (1 - activation_function(a, func))\n",
        "\n",
        "  if(func == ActivationFunction.RELU):\n",
        "    result = a.copy()\n",
        "    result[result>=0] = 1\n",
        "    result[result<0] = 0\n",
        "    return result\n",
        "  \n",
        "  if(func == ActivationFunction.TAN_H):\n",
        "    return 1 - np.square(activation_function(a, func))\n",
        "\n",
        "\n",
        "\n",
        "def output_function(a, func):\n",
        "  \"\"\"\n",
        "  Given the pre-activation values, post activation values of the output layer\n",
        "  \"\"\"\n",
        "  if(func == OutputFunction.SOFTMAX): \n",
        "    # a = a - np.max(a)\n",
        "    # return np.exp(a) / np.sum(np.exp(a), axis=1, keepdims=True)\n",
        "    num = np.exp(a - ((np.ones(shape=(a.shape[1],a.shape[0]))* (np.max(a,axis=1))).transpose()))\n",
        "    den = ((np.ones(shape=(a.shape[1],a.shape[0]))* (1/(np.sum(num,axis=1)))).transpose())\n",
        "    return np.multiply(num,den)\n",
        "\n",
        "\n",
        "def calc_total_error(predicted_distribution, true_label, method):\n",
        "  \"\"\"Calculates the total error based on the error calculation method\n",
        "  \n",
        "  Params:\n",
        "  --------\n",
        "  predicted_distribution:\n",
        "    ndarray containing the predicted probability distribution for each input\n",
        "  true label:\n",
        "    ndarray containing the true label for each inputs\n",
        "  method:\n",
        "    Enum describing the type of error calculation method used\n",
        "  \"\"\"\n",
        "  if(method == ErrorCalculationMethod.CROSS_ENTROPY):\n",
        "    rows = np.arange(true_label.shape[0]) #setting row number from 0 to length(true label)\n",
        "    cols = true_label\n",
        "    predicted_distribution = predicted_distribution[rows,cols]\n",
        "    predicted_distribution[predicted_distribution == 0] = 1e-6  #setting 0 values to very small value, so we dont get inf \n",
        "    return sum(-np.log(predicted_distribution)) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft8laK_twVri"
      },
      "source": [
        "# Main Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3Wcr7PFwVrj"
      },
      "outputs": [],
      "source": [
        "class Classification:\n",
        "  weight = []\n",
        "  bias = []\n",
        "  def __init__(self, _no_of_class, _hidden_layer, _input_layer, _max_epoch, _optimization_algorithm=OptimizationAlgorithm.SGD, _activation_fun=ActivationFunction.RELU, _initialization_method=InitializationMethod.UNIFORM_XAVIER, _output_function = OutputFunction.SOFTMAX, _error_calculation=ErrorCalculationMethod.CROSS_ENTROPY, _learning_rate = 0.01, _batch_size = 32, _momentum = 0.99, _decay_rate_for_update = 0.9) -> None:\n",
        "    self.no_of_class = _no_of_class\n",
        "    self.hidden_layer = _hidden_layer\n",
        "    self.activation_func = _activation_fun\n",
        "    self.max_epoch = _max_epoch\n",
        "    self.input_layer = _input_layer\n",
        "    self.output_func = _output_function\n",
        "    self.learning_rate = _learning_rate\n",
        "    self.initialization_method = _initialization_method\n",
        "    self.error_calculation = _error_calculation\n",
        "    self.L = len(_hidden_layer) + 1\n",
        "    self.optimization_algorithm = _optimization_algorithm\n",
        "    self.batch_size = _batch_size\n",
        "    self.momentum = _momentum\n",
        "    self.decay_rate_for_update = _decay_rate_for_update\n",
        "\n",
        "\n",
        "  def set_weight_and_bias(self):\n",
        "    #appending all these in a single list (easy for initializing w and b)\n",
        "    layer = [self.input_layer]\n",
        "    layer = layer + self.hidden_layer\n",
        "    layer.append(self.no_of_class)\n",
        "\n",
        "    #going to use 1-based indexing (as tought in the class)\n",
        "    #so adding some random matrix in 0-th index\n",
        "    w = [np.random.rand(1,1)]\n",
        "    b = [np.random.rand(1,1)]\n",
        "    prev_w = [np.random.rand(1,1)]\n",
        "    prev_b = [np.random.rand(1,1)]\n",
        "    prev_m = [np.random.rand(1,1)]\n",
        "    if(self.initialization_method == InitializationMethod.UNIFORM_RANDOM): \n",
        "      low = -1\n",
        "      high = 1\n",
        "      i = 1\n",
        "      while i < len(layer):\n",
        "        w.append(np.random.uniform(low, high, size=(layer[i], layer[i-1])))\n",
        "        b.append(np.zeros(layer[i]))\n",
        "        prev_w.append(np.zeros(shape=(layer[i], layer[i-1])))\n",
        "        prev_m.append(np.zeros(shape=(layer[i], layer[i-1])))\n",
        "        prev_b.append(np.zeros(layer[i]))\n",
        "        i +=1\n",
        "    \n",
        "    if(self.initialization_method == InitializationMethod.UNIFORM_XAVIER): \n",
        "      for i in range(1, len(layer)):\n",
        "        inputs = layer[i-1]\n",
        "        outputs = layer[i]\n",
        "        # x = math.sqrt(6/ inputs+outputs)\n",
        "        x = math.sqrt(1/inputs)\n",
        "        w.append(np.random.uniform(low=-x, high=x, size=(layer[i], layer[i-1])))\n",
        "        prev_m.append(np.zeros(shape=(layer[i], layer[i-1])))\n",
        "        b.append(np.zeros(layer[i]))\n",
        "        prev_w.append(np.zeros(shape=(layer[i], layer[i-1])))\n",
        "        prev_b.append(np.zeros(layer[i]))\n",
        "\n",
        "    if(self.initialization_method == InitializationMethod.GAUSSIAN_XAVIER): \n",
        "      mu = 0.0\n",
        "      for i in range(1, len(layer)):\n",
        "        inputs = layer[i-1]\n",
        "        outputs = layer[i]\n",
        "        # sigma = math.sqrt(6 / inputs+outputs)\n",
        "        sigma = math.sqrt(1/ inputs)\n",
        "        w.append(np.random.normal(mu, sigma, size=(layer[i], layer[i-1])))\n",
        "        prev_m.append(np.zeros(shape=(layer[i], layer[i-1])))\n",
        "        b.append(np.zeros(layer[i]))\n",
        "        prev_w.append(np.zeros(shape=(layer[i], layer[i-1])))\n",
        "        prev_b.append(np.zeros(layer[i]))\n",
        "    self.weight = w\n",
        "    self.bias = b\n",
        "    self.prev_weight = prev_w \n",
        "    self.prev_bias = prev_b\n",
        "    self.prev_moment = prev_m\n",
        "\n",
        "\n",
        "  def forward_propogation(self, input_images):\n",
        "    #for using 1 based indexing, adding some random matrix in 0-th index\n",
        "    a = [np.random.rand(1,1)]\n",
        "    h = [input_images]\n",
        "\n",
        "    for i in range(1, self.L):\n",
        "      a.append(self.bias[i] + np.dot(h[i-1], self.weight[i].T))\n",
        "      h.append(activation_function(a[i], self.activation_func))\n",
        "\n",
        "    a.append(self.bias[self.L] + np.dot(h[self.L-1], self.weight[self.L].T))\n",
        "    h.append(output_function(a[-1], self.output_func))\n",
        "    return a, h\n",
        "\n",
        "\n",
        "  def backward_propogation(self, a, h, true_label, weight = None):\n",
        "    if(weight == None):\n",
        "      weight = self.weight\n",
        "\n",
        "    del_a = [None] * (self.L+1)\n",
        "    del_h = [None] * (self.L+1)\n",
        "    del_w = [None] * (self.L+1)\n",
        "    del_b = [None] * (self.L+1)\n",
        "    \n",
        "    #computing del_a_l\n",
        "    del_a[-1] = h[-1].copy()\n",
        "    row_ind = np.arange(true_label.shape[0]) #creating numbers 0 to batch size (for row indices)\n",
        "    del_a[-1][row_ind,true_label] -= 1\n",
        "\n",
        "    for k in range(self.L, 0, -1):\n",
        "      #computing gradients w.r.t parameters\n",
        "      del_w[k] = np.dot(del_a[k].T, h[k-1])\n",
        "      del_b[k] = np.sum(del_a[k], axis=0)\n",
        "\n",
        "      #computing gradients w.r.t layer below (post-activation)\n",
        "      del_h[k-1] = np.dot(del_a[k],weight[k])\n",
        "\n",
        "      #computing gradients w.r.t layer below (pre-activation)\n",
        "      del_a[k-1] = del_h[k-1] * df_activation_function(a[k-1], self.activation_func)\n",
        "    \n",
        "    #setting the 0-th index to some random array of (1,1)\n",
        "    #so that it won't cause dimention mismatch\n",
        "    del_w[0] = np.random.rand(1,1)\n",
        "    del_b[0] = np.random.rand(1,1)\n",
        "    return del_w, del_b\n",
        "\n",
        "\n",
        "  def fit(self, x_train, y_train): \n",
        "    self.data_size = x_train.shape[0]\n",
        "    error_list = []\n",
        "    if(self.optimization_algorithm == OptimizationAlgorithm.GD):\n",
        "      for i in range(self.max_epoch):\n",
        "        a, h = self.forward_propogation(x_train)\n",
        "        del_w, del_b = self.backward_propogation(a, h, y_train) \n",
        "        if(i in [0, 10, 50, 100, 200, 400]):\n",
        "          print(\"{} th iteration\".format(i))\n",
        "          print(\"del w\", del_w)\n",
        "          print(\"del b\", del_b)\n",
        "\n",
        "        #converting to ndarray for easier calculations\n",
        "        del_w = np.array(del_w, dtype=object)\n",
        "        del_b = np.array(del_b, dtype=object)\n",
        "        if(self.activation_func == ActivationFunction.RELU):\n",
        "          #dividing by the batch size\n",
        "          del_w /= self.data_size\n",
        "          del_b /= self.data_size\n",
        "        if(i in [0, 10, 50, 100, 200, 400]):\n",
        "          print(\"type of weight \", type(self.weight))\n",
        "          print(\"type of bias \", type(self.bias))\n",
        "        self.weight -= self.learning_rate * del_w\n",
        "        self.bias -= self.learning_rate * del_b\n",
        "        err = calc_total_error(h[-1], y_train, self.error_calculation) / self.data_size\n",
        "        error_list.append(err)\n",
        "        print(\"Completed epoch : {} \\t Error: {}\".format(i, err))\n",
        "    \n",
        "    if(self.optimization_algorithm == OptimizationAlgorithm.MINI_BATCH):\n",
        "      no_of_batches = self.data_size // self.batch_size\n",
        "      for i in range(self.max_epoch):\n",
        "        err = 0\n",
        "        for j in range(no_of_batches+1): \n",
        "          begin = j * self.batch_size\n",
        "          end = begin + self.batch_size\n",
        "          if(end > self.data_size):\n",
        "            end = self.data_size\n",
        "\n",
        "          a, h = self.forward_propogation(x_train[begin:end])\n",
        "          del_w, del_b = self.backward_propogation(a, h, y_train[begin:end])\n",
        "\n",
        "          #converting to ndarray for easier calculations\n",
        "          del_w = np.array(del_w, dtype=object)\n",
        "          del_b = np.array(del_b, dtype=object)\n",
        "          self.weight -= self.learning_rate * del_w\n",
        "          self.bias -= self.learning_rate * del_b\n",
        "          err += calc_total_error(h[-1], y_train[begin:end], self.error_calculation)\n",
        "        err /= self.data_size\n",
        "        error_list.append(err)\n",
        "        print(\"Completed epoch : {} \\t Error: {}\".format(i, err))\n",
        "    \n",
        "    if(self.optimization_algorithm == OptimizationAlgorithm.SGD): #same as above code, but with batch size = 1\n",
        "      self.batch_size = 1\n",
        "      no_of_batches = self.data_size // self.batch_size\n",
        "      for i in range(self.max_epoch):\n",
        "        err = 0\n",
        "        for j in range(no_of_batches+1): \n",
        "          begin = j * self.batch_size\n",
        "          end = begin + self.batch_size\n",
        "          if(end > self.data_size):\n",
        "            end = self.data_size\n",
        "\n",
        "          a, h = self.forward_propogation(x_train[begin:end])\n",
        "          del_w, del_b = self.backward_propogation(a, h, y_train[begin:end])\n",
        "\n",
        "          #converting to ndarray for easier calculations\n",
        "          del_w = np.array(del_w, dtype=object) / self.batch_size\n",
        "          del_b = np.array(del_b, dtype=object) / self.batch_size\n",
        "          self.weight -= self.learning_rate * del_w\n",
        "          self.bias -= self.learning_rate * del_b\n",
        "          err += calc_total_error(h[-1], y_train[begin:end], self.error_calculation)\n",
        "        err /= self.data_size\n",
        "        error_list.append(err)\n",
        "        print(\"Completed epoch : {} \\t Error: {}\".format(i, err))\n",
        "    \n",
        "    if(self.optimization_algorithm == OptimizationAlgorithm.MOMENTUM_GD):\n",
        "      no_of_batches = self.data_size // self.batch_size\n",
        "\n",
        "      #converting to ndarray for faster calculation ( #todo: why not return it as ndarray )\n",
        "      prev_w = np.array(self.prev_weight, dtype=object)\n",
        "      prev_b = np.array(self.prev_bias, dtype=object)\n",
        "      for i in range(self.max_epoch):\n",
        "        err = 0\n",
        "        for j in range(no_of_batches+1):\n",
        "          begin = j * self.batch_size\n",
        "          end = begin + self.batch_size\n",
        "          if(end > self.data_size):\n",
        "            end = self.data_size\n",
        "          \n",
        "          a, h = self.forward_propogation(x_train[begin:end])\n",
        "          del_w, del_b = self.backward_propogation(a, h, y_train[begin:end])\n",
        "\n",
        "          #converting to ndarray for easier calculations\n",
        "          del_w = np.array(del_w, dtype=object)\n",
        "          del_b = np.array(del_b, dtype=object)\n",
        "          prev_w = self.momentum * prev_w + (1 - self.momentum) * del_w\n",
        "          prev_b = self.momentum * prev_b + (1 - self.momentum) * del_b\n",
        "\n",
        "          self.weight -= self.learning_rate * prev_w\n",
        "          self.bias -= self.learning_rate * prev_b\n",
        "          err += calc_total_error(h[-1], y_train[begin:end], self.error_calculation)\n",
        "        err /= self.data_size\n",
        "        error_list.append(err)\n",
        "        print(\"Completed epoch : {} \\t Error: {}\".format(i, err))\n",
        "\n",
        "    if(self.optimization_algorithm == OptimizationAlgorithm.NAG):\n",
        "      no_of_batches = self.data_size // self.batch_size\n",
        "\n",
        "      #converting to ndarray for faster calculation ( #todo: why not return it as ndarray )\n",
        "      prev_w = np.array(self.prev_weight, dtype=object)\n",
        "      prev_b = np.array(self.prev_bias, dtype=object)\n",
        "      for i in range(self.max_epoch):\n",
        "        err = 0\n",
        "        for j in range(no_of_batches+1):\n",
        "          begin = j * self.batch_size\n",
        "          end = begin + self.batch_size\n",
        "          if(end > self.data_size):\n",
        "            end = self.data_size\n",
        "          \n",
        "          a, h = self.forward_propogation(x_train[begin:end])\n",
        "          w_lookahead = self.weight - self.momentum * prev_w\n",
        "          del_w_lookahead, del_b = self.backward_propogation(a, h, y_train[begin:end],weight=w_lookahead)\n",
        "\n",
        "          #converting to ndarray for easier calculations\n",
        "          del_w_lookahead = np.array(del_w_lookahead, dtype=object)\n",
        "          del_b = np.array(del_b, dtype=object)\n",
        "          prev_w = self.momentum * prev_w + (1 - self.momentum) * del_w_lookahead\n",
        "          prev_b = self.momentum * prev_b + (1 - self.momentum) * del_b\n",
        "\n",
        "          self.weight -= self.learning_rate * prev_w\n",
        "          self.bias -= self.learning_rate * prev_b\n",
        "          err += calc_total_error(h[-1], y_train[begin:end], self.error_calculation)\n",
        "        err /= self.data_size\n",
        "        error_list.append(err)\n",
        "        print(\"Completed epoch : {} \\t Error: {}\".format(i, err))\n",
        "\n",
        "    if(self.optimization_algorithm == OptimizationAlgorithm.RMS_PROP):\n",
        "      no_of_batches = self.data_size // self.batch_size\n",
        "      eta = 1e-7 #a very small constant \n",
        "\n",
        "      #converting to ndarray for faster calculation ( #todo: why not return it as ndarray )\n",
        "      prev_w = np.array(self.prev_weight, dtype=object)\n",
        "      prev_b = np.array(self.prev_bias, dtype=object)\n",
        "      for i in range(self.max_epoch):\n",
        "        err = 0\n",
        "        for j in range(no_of_batches+1):\n",
        "          begin = j * self.batch_size\n",
        "          end = begin + self.batch_size\n",
        "          if(end > self.data_size):\n",
        "            end = self.data_size\n",
        "          \n",
        "          a, h = self.forward_propogation(x_train[begin:end])\n",
        "          del_w, del_b = self.backward_propogation(a, h, y_train[begin:end])\n",
        "\n",
        "          #converting to ndarray for easier calculations\n",
        "          del_w = np.array(del_w, dtype=object)\n",
        "          del_b = np.array(del_b, dtype=object)\n",
        "\n",
        "          prev_w = self.momentum * prev_w + (1 - self.momentum) * np.square(del_w)\n",
        "          prev_b = self.momentum * prev_b + (1 - self.momentum) * np.square(del_b)\n",
        "\n",
        "          new_lr_w = self.learning_rate / (prev_w**0.5 + eta)\n",
        "          new_lr_b = self.learning_rate / (prev_b**0.5 + eta)\n",
        "\n",
        "          self.weight -= new_lr_w * del_w\n",
        "          self.bias -= new_lr_b * del_b\n",
        "          err += calc_total_error(h[-1], y_train[begin:end], self.error_calculation)\n",
        "        err /= self.data_size\n",
        "        error_list.append(err)\n",
        "        print(\"Completed epoch : {} \\t Error: {}\".format(i, err))\n",
        "    \n",
        "    if(self.optimization_algorithm == OptimizationAlgorithm.ADAM):\n",
        "      no_of_batches = self.data_size // self.batch_size\n",
        "      eta = 1e-8 #a very small constant \n",
        "\n",
        "      #converting to ndarray for faster calculation ( #todo: why not return it as ndarray )\n",
        "      prev_w = np.array(self.prev_weight, dtype=object)\n",
        "      prev_b = np.array(self.prev_bias, dtype=object)\n",
        "      prev_update_w = prev_w.copy()\n",
        "      prev_update_b = prev_b.copy()\n",
        "      for i in range(self.max_epoch):\n",
        "        err = 0\n",
        "        for j in range(no_of_batches+1):\n",
        "          begin = j * self.batch_size\n",
        "          end = begin + self.batch_size\n",
        "          if(end > self.data_size):\n",
        "            end = self.data_size\n",
        "          \n",
        "          a, h = self.forward_propogation(x_train[begin:end])\n",
        "          del_w, del_b = self.backward_propogation(a, h, y_train[begin:end])\n",
        "\n",
        "          #converting to ndarray for easier calculations\n",
        "          del_w = np.array(del_w, dtype=object)\n",
        "          del_b = np.array(del_b, dtype=object)\n",
        "\n",
        "          prev_w = self.momentum * prev_w + (1 - self.momentum) * del_w\n",
        "          prev_w_hat = prev_w / (1 - self.momentum)\n",
        "          prev_b = self.momentum * prev_b + (1 - self.momentum) * del_b\n",
        "          prev_b_hat = prev_b / (1 - self.momentum)\n",
        "\n",
        "          prev_update_w = self.momentum * prev_update_w + (1 - self.momentum) * np.square(del_w)\n",
        "          prev_update_m_hat = prev_update_w / (1 - self.momentum)\n",
        "          prev_update_b = self.momentum * prev_update_b + (1 - self.momentum) * np.square(del_b)\n",
        "          prev_update_b_hat = prev_update_b / (1 - self.momentum)\n",
        "\n",
        "          new_lr_w = self.learning_rate / (prev_update_m_hat**0.5 + eta)\n",
        "          new_lr_b = self.learning_rate / (prev_update_b_hat**0.5 + eta)\n",
        "\n",
        "          self.weight -= new_lr_w * prev_w_hat\n",
        "          self.bias -= new_lr_b * prev_b_hat\n",
        "          err += calc_total_error(h[-1], y_train[begin:end], self.error_calculation)\n",
        "        err /= self.data_size\n",
        "        error_list.append(err)\n",
        "        print(\"Completed epoch : {} \\t Error: {}\".format(i, err))\n",
        "      \n",
        "    if(self.optimization_algorithm == OptimizationAlgorithm.NADAM):\n",
        "      no_of_batches = self.data_size // self.batch_size\n",
        "      eta = 1e-8 #a very small constant \n",
        "\n",
        "      #converting to ndarray for faster calculation ( #todo: why not return it as ndarray )\n",
        "      prev_w = np.array(self.prev_weight, dtype=object)\n",
        "      prev_b = np.array(self.prev_bias, dtype=object)\n",
        "      prev_update_w = prev_w.copy()\n",
        "      prev_update_b = prev_b.copy()\n",
        "      for i in range(self.max_epoch):\n",
        "        err = 0\n",
        "        for j in range(no_of_batches+1):\n",
        "          begin = j * self.batch_size\n",
        "          end = begin + self.batch_size\n",
        "          if(end > self.data_size):\n",
        "            end = self.data_size\n",
        "          \n",
        "          a, h = self.forward_propogation(x_train[begin:end])\n",
        "          del_w, del_b = self.backward_propogation(a, h, y_train[begin:end])\n",
        "\n",
        "          #converting to ndarray for easier calculations\n",
        "          del_w = np.array(del_w, dtype=object)\n",
        "          del_b = np.array(del_b, dtype=object)\n",
        "\n",
        "          prev_w = self.momentum * prev_w + (1 - self.momentum) * del_w\n",
        "          prev_w_hat = prev_w / (1 - self.momentum)\n",
        "          prev_b = self.momentum * prev_b + (1 - self.momentum) * del_b\n",
        "          prev_b_hat = prev_b / (1 - self.momentum)\n",
        "\n",
        "          prev_update_w = self.momentum * prev_update_w + (1 - self.momentum) * np.square(del_w)\n",
        "          prev_update_m_hat = prev_update_w / (1 - self.momentum)\n",
        "          prev_update_b = self.momentum * prev_update_b + (1 - self.momentum) * np.square(del_b)\n",
        "          prev_update_b_hat = prev_update_b / (1 - self.momentum)\n",
        "\n",
        "          new_lr_w = self.learning_rate / (prev_update_m_hat**0.5 + eta)\n",
        "          new_lr_b = self.learning_rate / (prev_update_b_hat**0.5 + eta)\n",
        "\n",
        "          print(\"tyrpe of WEIGHT\", type(self.weight))\n",
        "          print(\"tyrpe of BAIS\", type(self.bias))\n",
        "          self.weight -= new_lr_w * (self.momentum * prev_w_hat + (((1/self.momentum) * del_w) / (1-self.momentum)))\n",
        "          self.bias -= new_lr_b * (self.momentum * prev_b_hat + (((1/self.momentum) * del_b) / (1-self.momentum)))\n",
        "          err += calc_total_error(h[-1], y_train[begin:end], self.error_calculation)\n",
        "        err /= self.data_size\n",
        "        error_list.append(err)\n",
        "        print(\"Completed epoch : {} \\t Error: {}\".format(i, err))\n",
        "\n",
        "    plt.plot(error_list)\n",
        "    plt.show()\n",
        "\n",
        "        \n",
        "\n",
        "  def test(self, x_test, y_test):\n",
        "    print(\"x_test {} \\t y_test {}\".format(x_test.shape, y_test.shape))\n",
        "    _ , h = self.forward_propogation(x_test)\n",
        "    predicted_distribution = h[-1]\n",
        "    return calc_accuracy(np.argmax(predicted_distribution, axis=1), y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ35jZd2e7Jr"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WTEDUkt2Ip12",
        "outputId": "70e57c26-6482-48ad-f8f6-c57fe29e462f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tyrpe of WEIGHT <class 'list'>\n",
            "tyrpe of BAIS <class 'list'>\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mg:\\My Drive\\Colab Notebooks\\MNIST.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model1 \u001b[39m=\u001b[39m Classification(_no_of_class\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                        _hidden_layer\u001b[39m=\u001b[39m[\u001b[39m64\u001b[39m, \u001b[39m64\u001b[39m], \n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                        _input_layer\u001b[39m=\u001b[39m\u001b[39m784\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                        _decay_rate_for_update \u001b[39m=\u001b[39m \u001b[39m0.999\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                        _max_epoch\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model1\u001b[39m.\u001b[39mset_weight_and_bias()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model1\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n",
            "\u001b[1;32mg:\\My Drive\\Colab Notebooks\\MNIST.ipynb Cell 12\u001b[0m in \u001b[0;36mClassification.fit\u001b[1;34m(self, x_train, y_train)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=421'>422</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtyrpe of WEIGHT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight))\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=422'>423</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtyrpe of BAIS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias))\n\u001b[1;32m--> <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=423'>424</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m new_lr_w \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum \u001b[39m*\u001b[39m prev_w_hat \u001b[39m+\u001b[39m (((\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum) \u001b[39m*\u001b[39m del_w) \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum)))\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=424'>425</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m new_lr_b \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum \u001b[39m*\u001b[39m prev_b_hat \u001b[39m+\u001b[39m (((\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum) \u001b[39m*\u001b[39m del_b) \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmomentum)))\n\u001b[0;32m    <a href='vscode-notebook-cell:/g%3A/My%20Drive/Colab%20Notebooks/MNIST.ipynb#X14sZmlsZQ%3D%3D?line=425'>426</a>\u001b[0m err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalc_total_error(h[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], y_train[begin:end])\n",
            "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4,) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "#@title ReLU GD Small Data { vertical-output: true}\n",
        "model1 = Classification(_no_of_class=10, \n",
        "                       _hidden_layer=[64, 64], \n",
        "                       _input_layer=784,\n",
        "                       _initialization_method=InitializationMethod.UNIFORM_XAVIER,\n",
        "                       _learning_rate=0.001,\n",
        "                       _activation_fun=ActivationFunction.SIGMOID, \n",
        "                       _optimization_algorithm=OptimizationAlgorithm.NADAM,\n",
        "                       _batch_size = 32,\n",
        "                       _momentum = 0.9,\n",
        "                       _decay_rate_for_update = 0.999,\n",
        "                       _max_epoch=40)\n",
        "model1.set_weight_and_bias()\n",
        "\n",
        "\n",
        "model1.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uatJ31EmWZka",
        "outputId": "9b7f8218-c898-4143-ec44-7a7fe4efdb97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_test (10000, 784) \t y_test (10000,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7893"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.test(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooea0AoWB657"
      },
      "outputs": [],
      "source": [
        "#@title Sigmoid SDG Large data{vertical-output:true}\n",
        "model = Classification(_no_of_class=10, \n",
        "                       _hidden_layer=[32, 32], \n",
        "                       _input_layer=784,\n",
        "                       _initialization_method=InitializationMethod.UNIFORM_XAVIER,\n",
        "                       _learning_rate=0.01,\n",
        "                       _activation_fun=ActivationFunction.SIGMOID, \n",
        "                       _optimization_algorithm=OptimizationAlgorithm.SGD,\n",
        "                       _batch_size = 100,\n",
        "                       _max_epoch=15)\n",
        "\n",
        "model.set_weight_and_bias()\n",
        "\n",
        "model.fit(x_train[:10000], y_train[:10000])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9XXZ0fZmEUO6",
        "outputId": "4ad4f0b5-faa0-480d-df9e-67411dc4f0d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 th iteration\n",
            "del w [array([[0.6997775]]), array([[ 0.        ,  0.        ,  0.        , ...,  0.00145101,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00079434,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00034212,\n",
            "         0.        ,  0.        ],\n",
            "       ...,\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00035952,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ...,  0.0007237 ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00019484,\n",
            "         0.        ,  0.        ]]), array([[ 0.00948401,  0.01282576,  0.01111561, ...,  0.0126022 ,\n",
            "         0.00991595,  0.01468783],\n",
            "       [ 0.01484728,  0.0104087 ,  0.01184118, ...,  0.01279231,\n",
            "         0.00965658,  0.01452261],\n",
            "       [-0.01395345, -0.01628324, -0.01376209, ..., -0.01629257,\n",
            "        -0.01844165, -0.01635783],\n",
            "       ...,\n",
            "       [-0.01119052, -0.0171807 , -0.01372565, ..., -0.01472078,\n",
            "        -0.01179998, -0.01737038],\n",
            "       [ 0.02643289,  0.01875996,  0.02144334, ...,  0.02073216,\n",
            "         0.01910496,  0.02260818],\n",
            "       [ 0.05435093,  0.04313429,  0.04648246, ...,  0.04914627,\n",
            "         0.04583681,  0.05250145]]), array([[-0.98520151, -0.76626298, -0.76703223, -0.75716074, -1.11119522,\n",
            "        -1.02959459, -0.74736438, -0.68257608, -0.96318576, -0.69638819,\n",
            "        -1.05899184, -0.9690827 , -1.21662846, -1.1125901 , -0.86942948,\n",
            "        -0.98526294, -0.82375123, -0.7320731 , -0.93682894, -1.01202478,\n",
            "        -0.93362289, -1.13219656, -0.85594604, -0.81713596, -0.99552894,\n",
            "        -1.03979535, -0.87994514, -0.75367543, -1.00520574, -0.93901911,\n",
            "        -1.06357331, -0.98440747, -0.82430121, -0.90393378, -0.96688214,\n",
            "        -0.96904673, -0.75242643, -0.6874091 , -0.82708096, -0.97940472,\n",
            "        -0.74572916, -0.85407422, -0.79804325, -0.77196093, -0.7363964 ,\n",
            "        -1.01072014, -0.94353137, -0.69893473, -0.64916516, -1.00338273,\n",
            "        -0.93144562, -1.03069347, -0.81503603, -0.83197027, -1.06120257,\n",
            "        -0.95147332, -1.05525736, -0.94985053, -0.84682927, -0.75003135,\n",
            "        -1.03127595, -1.06468812, -0.92754708, -0.94015002],\n",
            "       [ 0.63778814,  0.48953765,  0.49445729,  0.4949874 ,  0.71204827,\n",
            "         0.66870542,  0.48027863,  0.43613361,  0.62068338,  0.45127612,\n",
            "         0.68845731,  0.63153996,  0.78579283,  0.71991893,  0.57061672,\n",
            "         0.6382737 ,  0.5246524 ,  0.47005947,  0.6096582 ,  0.65916989,\n",
            "         0.60975582,  0.73382501,  0.54957398,  0.53827198,  0.63560764,\n",
            "         0.6773779 ,  0.57964729,  0.48207216,  0.65467306,  0.61109882,\n",
            "         0.68430294,  0.64183267,  0.52829704,  0.58024901,  0.62816854,\n",
            "         0.63556774,  0.4917765 ,  0.44834036,  0.53302085,  0.62456529,\n",
            "         0.46818879,  0.56050057,  0.51811464,  0.49306611,  0.47927495,\n",
            "         0.64436101,  0.60967488,  0.43592454,  0.40194198,  0.64484922,\n",
            "         0.60418811,  0.66630341,  0.51985106,  0.53110781,  0.6847511 ,\n",
            "         0.61692293,  0.67097612,  0.61492644,  0.53840632,  0.48235093,\n",
            "         0.66955439,  0.68131963,  0.6080945 ,  0.59580545],\n",
            "       [-0.56953863, -0.41072714, -0.41399589, -0.42188168, -0.61207808,\n",
            "        -0.58375445, -0.41300834, -0.38709084, -0.53749712, -0.38199514,\n",
            "        -0.60992396, -0.57344089, -0.69078577, -0.63025788, -0.50406863,\n",
            "        -0.55917227, -0.45327799, -0.38315266, -0.51871548, -0.58622076,\n",
            "        -0.54543295, -0.65902134, -0.47362291, -0.44662717, -0.55555439,\n",
            "        -0.59939847, -0.50227212, -0.41405774, -0.56067427, -0.53144992,\n",
            "        -0.58040931, -0.55514734, -0.45109261, -0.51447191, -0.55076411,\n",
            "        -0.54666887, -0.42894989, -0.38100174, -0.46243152, -0.54619976,\n",
            "        -0.39013441, -0.50345195, -0.45687671, -0.41950694, -0.40469893,\n",
            "        -0.56249201, -0.53120725, -0.3645291 , -0.3425493 , -0.54062689,\n",
            "        -0.5203195 , -0.57587979, -0.43721472, -0.46275399, -0.60641202,\n",
            "        -0.53672142, -0.56323812, -0.53189584, -0.43395481, -0.42145384,\n",
            "        -0.56983176, -0.58011745, -0.53486385, -0.51168012],\n",
            "       [ 0.36178185,  0.27246305,  0.27862386,  0.28102172,  0.39871883,\n",
            "         0.37494265,  0.27086487,  0.24460495,  0.35321389,  0.25636643,\n",
            "         0.39300739,  0.35931046,  0.44085486,  0.40775514,  0.32484298,\n",
            "         0.36915853,  0.29830543,  0.26509039,  0.34633697,  0.37856414,\n",
            "         0.34790919,  0.41507661,  0.30448397,  0.29848208,  0.35684259,\n",
            "         0.38876925,  0.32877717,  0.27058893,  0.37399898,  0.34990974,\n",
            "         0.37963102,  0.35994296,  0.30122782,  0.32667944,  0.35539042,\n",
            "         0.3543932 ,  0.27808511,  0.2524641 ,  0.30203344,  0.35525859,\n",
            "         0.26192473,  0.31186219,  0.29092884,  0.281235  ,  0.26527305,\n",
            "         0.36211878,  0.34655099,  0.23655809,  0.22562418,  0.36031078,\n",
            "         0.34294467,  0.3815116 ,  0.29078168,  0.29380065,  0.38306937,\n",
            "         0.34953087,  0.37473508,  0.34956391,  0.30077262,  0.27086904,\n",
            "         0.38009806,  0.38104653,  0.34937756,  0.33259903],\n",
            "       [ 0.54234741,  0.41629936,  0.42046131,  0.42090919,  0.60552666,\n",
            "         0.56863819,  0.40841931,  0.37087455,  0.52780067,  0.38373927,\n",
            "         0.58543454,  0.53703663,  0.66821591,  0.61219799,  0.48522777,\n",
            "         0.54275851,  0.44616714,  0.3997178 ,  0.51842565,  0.56052409,\n",
            "         0.51851373,  0.62401948,  0.46733178,  0.45773831,  0.54052445,\n",
            "         0.57600859,  0.49289626,  0.40995402,  0.55673541,  0.51963718,\n",
            "         0.58192119,  0.54579378,  0.44923217,  0.49343578,  0.53416743,\n",
            "         0.54044413,  0.41818207,  0.38126555,  0.45324931,  0.53111516,\n",
            "         0.398138  ,  0.47663676,  0.44058519,  0.41928183,  0.40756839,\n",
            "         0.54795803,  0.51844834,  0.37072183,  0.34180587,  0.54837086,\n",
            "         0.51378105,  0.56660143,  0.4420651 ,  0.45165301,  0.58228993,\n",
            "         0.52461276,  0.57059635,  0.52289591,  0.45785819,  0.41017034,\n",
            "         0.56938059,  0.57939474,  0.51709096,  0.50666641],\n",
            "       [-0.70642113, -0.57094842, -0.57698744, -0.58156729, -0.79011192,\n",
            "        -0.77130593, -0.54769475, -0.48309542, -0.70544741, -0.51708247,\n",
            "        -0.77443682, -0.69910586, -0.88868708, -0.80847233, -0.65374663,\n",
            "        -0.72540035, -0.603305  , -0.56307819, -0.7048845 , -0.74911886,\n",
            "        -0.67765416, -0.81971416, -0.62937061, -0.62931829, -0.70734391,\n",
            "        -0.77042331, -0.66882402, -0.54043657, -0.7403873 , -0.69836661,\n",
            "        -0.79577594, -0.74198941, -0.6115879 , -0.65331817, -0.71420823,\n",
            "        -0.74372545, -0.56652072, -0.51784055, -0.61346778, -0.69540956,\n",
            "        -0.52644261, -0.6366906 , -0.57773012, -0.56115763, -0.56269284,\n",
            "        -0.72429056, -0.70044341, -0.48756379, -0.45157338, -0.74086343,\n",
            "        -0.71187907, -0.75944314, -0.58190531, -0.59317157, -0.7700712 ,\n",
            "        -0.70873473, -0.78189911, -0.6961647 , -0.6285364 , -0.54970749,\n",
            "        -0.77158511, -0.76550834, -0.68916933, -0.68075287],\n",
            "       [ 0.46977101,  0.36058007,  0.3642123 ,  0.36460587,  0.52447187,\n",
            "         0.49255498,  0.35375726,  0.32123058,  0.45717556,  0.3324052 ,\n",
            "         0.50709326,  0.46516594,  0.57878871,  0.53026566,  0.42030282,\n",
            "         0.47012203,  0.38644033,  0.34624252,  0.44906751,  0.48551997,\n",
            "         0.44912039,  0.54050509,  0.40480778,  0.39649739,  0.46815924,\n",
            "         0.49893632,  0.42695863,  0.35506974,  0.48220919,  0.4501281 ,\n",
            "         0.50405211,  0.47276881,  0.38912642,  0.42738511,  0.46269118,\n",
            "         0.46816087,  0.3622347 ,  0.33024084,  0.39261629,  0.46002989,\n",
            "         0.34484763,  0.41284868,  0.38161951,  0.36317751,  0.35302671,\n",
            "         0.47461302,  0.44905783,  0.32108697,  0.29604726,  0.47498602,\n",
            "         0.44503657,  0.49077952,  0.38291219,  0.39118743,  0.50436355,\n",
            "         0.45441101,  0.4942227 ,  0.45293951,  0.39657417,  0.35529241,\n",
            "         0.49317688,  0.50183657,  0.44791096,  0.43884554],\n",
            "       [-0.25149094, -0.18837717, -0.18855944, -0.19050594, -0.28650598,\n",
            "        -0.25413422, -0.19096083, -0.16239112, -0.24065287, -0.17625544,\n",
            "        -0.27097136, -0.24567401, -0.29995986, -0.28259975, -0.2223984 ,\n",
            "        -0.25178196, -0.20894661, -0.1779573 , -0.24112909, -0.25638126,\n",
            "        -0.24632646, -0.2834358 , -0.20384738, -0.22360027, -0.25260167,\n",
            "        -0.2659017 , -0.22530842, -0.19511061, -0.27750348, -0.23908376,\n",
            "        -0.26263811, -0.24912007, -0.19492905, -0.22432091, -0.24163531,\n",
            "        -0.24107723, -0.18765276, -0.18467833, -0.20171799, -0.24421302,\n",
            "        -0.17933339, -0.21519844, -0.20654239, -0.19062371, -0.18531895,\n",
            "        -0.24715656, -0.23204555, -0.16723909, -0.14386221, -0.25320919,\n",
            "        -0.23129885, -0.2673119 , -0.2034826 , -0.20669662, -0.26090805,\n",
            "        -0.24184946, -0.25612442, -0.23716656, -0.21411836, -0.18367478,\n",
            "        -0.27181094, -0.27396637, -0.24431853, -0.22240026],\n",
            "       [ 0.54701793,  0.41992522,  0.42412516,  0.42457526,  0.61073374,\n",
            "         0.57357898,  0.41195119,  0.37406874,  0.53237201,  0.38706987,\n",
            "         0.59048356,  0.54165483,  0.67399775,  0.61747322,  0.48942919,\n",
            "         0.54744568,  0.45004147,  0.40322432,  0.52292701,  0.56537463,\n",
            "         0.52296699,  0.62939754,  0.47140368,  0.46171141,  0.54517794,\n",
            "         0.58099217,  0.49716194,  0.41348351,  0.56151014,  0.52414757,\n",
            "         0.58699532,  0.55053546,  0.45314587,  0.49770053,  0.53878689,\n",
            "         0.54516263,  0.42181602,  0.38456391,  0.45719782,  0.53569826,\n",
            "         0.40158588,  0.48075623,  0.44437361,  0.42291715,  0.41111682,\n",
            "         0.55269621,  0.52293569,  0.37393511,  0.34477688,  0.55312967,\n",
            "         0.51826803,  0.57150389,  0.44588735,  0.45554557,  0.58732542,\n",
            "         0.52916045,  0.57556952,  0.52741894,  0.46183643,  0.41373929,\n",
            "         0.57430481,  0.58438956,  0.52155544,  0.51106979],\n",
            "       [-0.04605412, -0.02248964, -0.03530492, -0.03498379, -0.05160818,\n",
            "        -0.03963103, -0.02624296, -0.03175898, -0.04446234, -0.03913564,\n",
            "        -0.05015207, -0.04740436, -0.0515889 , -0.05369087, -0.04077634,\n",
            "        -0.04614091, -0.01632593, -0.02807325, -0.04485733, -0.04540707,\n",
            "        -0.04522966, -0.04845587, -0.03481425, -0.03601949, -0.03528294,\n",
            "        -0.04656541, -0.0490916 , -0.02788801, -0.045356  , -0.04700199,\n",
            "        -0.0345059 , -0.04020938, -0.03911856, -0.0294051 , -0.04571466,\n",
            "        -0.0432103 , -0.03654461, -0.02594505, -0.03341946, -0.04144013,\n",
            "        -0.03304546, -0.03318922, -0.03642931, -0.03642839, -0.0271528 ,\n",
            "        -0.0370878 , -0.03944014, -0.01995983, -0.02304613, -0.04356432,\n",
            "        -0.02927538, -0.04337155, -0.04385873, -0.02870203, -0.04320553,\n",
            "        -0.03585911, -0.02958076, -0.05266706, -0.0320089 , -0.02755453,\n",
            "        -0.04201095, -0.04370675, -0.04813063, -0.03000297]])]\n",
            "del b [array([[0.84540373]]), array([ 0.01364616, -0.0048399 , -0.0076155 ,  0.01768105,  0.00017605,\n",
            "       -0.01752037, -0.00162522, -0.00902282,  0.00616082, -0.0024677 ,\n",
            "        0.00452247, -0.00804472, -0.00770788,  0.00344359,  0.00303713,\n",
            "        0.00361463,  0.01217535,  0.00591284,  0.01055443,  0.00558376,\n",
            "        0.00962684, -0.0145894 , -0.00420807, -0.01168385, -0.01129159,\n",
            "        0.00057833,  0.0103883 , -0.0131869 ,  0.01063202,  0.00060596,\n",
            "       -0.00384006,  0.00258383,  0.00805152, -0.00922789, -0.00307429,\n",
            "       -0.00255404, -0.00132151,  0.00679361, -0.00471668,  0.00948375,\n",
            "       -0.00357812,  0.00310866, -0.00745477,  0.00162704, -0.0015065 ,\n",
            "       -0.00272557,  0.00022752,  0.0046422 ,  0.01445843, -0.00159486,\n",
            "       -0.00482557,  0.00488642,  0.00047975, -0.00788308, -0.00232901,\n",
            "        0.00638791, -0.00232227, -0.00456194,  0.00415421, -0.00246328,\n",
            "       -0.00049663, -0.00047061,  0.00943161,  0.00280096]), array([ 0.02898978,  0.02465617, -0.0359142 ,  0.05525565,  0.02616975,\n",
            "        0.03354307, -0.0154272 ,  0.05799703,  0.05696178,  0.03480264,\n",
            "       -0.02810582,  0.05867177, -0.00825891,  0.07484886, -0.05899134,\n",
            "        0.03186104,  0.09154654,  0.02148328,  0.05540928,  0.06606708,\n",
            "        0.03191376, -0.01815775,  0.07263934, -0.05221549,  0.00236735,\n",
            "        0.0139997 , -0.04615504,  0.0079563 ,  0.03169745, -0.05402123,\n",
            "       -0.01591264, -0.0037951 , -0.07331296,  0.08100278, -0.02878716,\n",
            "        0.00611537,  0.02779097,  0.06550313,  0.05235294, -0.07322375,\n",
            "        0.0290157 , -0.06500394, -0.06729456,  0.00674762, -0.03876761,\n",
            "       -0.06241174, -0.0281699 , -0.053885  , -0.08491052, -0.00537374,\n",
            "        0.06763498,  0.09500694, -0.08440662,  0.16964641, -0.10856339,\n",
            "       -0.03722047, -0.05188551,  0.04310302, -0.08151752,  0.00258785,\n",
            "       -0.00525776, -0.03221167,  0.04025584,  0.10061246]), array([-1.78166519,  1.15131928, -0.99937302,  0.64972243,  0.9790435 ,\n",
            "       -1.30925525,  0.84802986, -0.44855468,  0.98751817, -0.07678509])]\n",
            "type of weight  <class 'list'>\n",
            "type of bias  <class 'list'>\n",
            "Completed epoch : 0 \t Error: 2.332946913638594\n",
            "Completed epoch : 1 \t Error: 2.1600724521732126\n",
            "Completed epoch : 2 \t Error: 2.0484601005368455\n",
            "Completed epoch : 3 \t Error: 1.9756413796471506\n",
            "Completed epoch : 4 \t Error: 1.9261584736347934\n",
            "Completed epoch : 5 \t Error: 1.8908828224025078\n",
            "Completed epoch : 6 \t Error: 1.8646307209368023\n",
            "Completed epoch : 7 \t Error: 1.8443652516822902\n",
            "Completed epoch : 8 \t Error: 1.82821994833597\n",
            "Completed epoch : 9 \t Error: 1.815003544767034\n",
            "10 th iteration\n",
            "del w [array([[0.03914872]]), array([[ 0.        ,  0.        ,  0.        , ...,  0.00100507,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00068339,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00033242,\n",
            "         0.        ,  0.        ],\n",
            "       ...,\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00052969,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ...,  0.00052443,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00029527,\n",
            "         0.        ,  0.        ]]), array([[-0.01213427, -0.00505156, -0.00785264, ..., -0.00817138,\n",
            "        -0.01093177, -0.00802472],\n",
            "       [-0.00326756, -0.0061495 , -0.00499583, ..., -0.00573844,\n",
            "        -0.00689429, -0.00456448],\n",
            "       [-0.00307205, -0.00515135, -0.00312498, ..., -0.00495089,\n",
            "        -0.00703961, -0.00443647],\n",
            "       ...,\n",
            "       [-0.00129449, -0.0070152 , -0.00319643, ..., -0.00410066,\n",
            "        -0.00060392, -0.00578966],\n",
            "       [ 0.01007587,  0.00390982,  0.00666772, ...,  0.00423235,\n",
            "         0.00485858,  0.00590647],\n",
            "       [ 0.01294441,  0.00731165,  0.01075379, ...,  0.00968433,\n",
            "         0.00760207,  0.01103736]]), array([[-0.07861967, -0.07763734, -0.07008606, -0.0579681 , -0.10390214,\n",
            "        -0.08877921, -0.07400456, -0.0683634 , -0.08164221, -0.0660191 ,\n",
            "        -0.08431558, -0.07738476, -0.09819439, -0.09662179, -0.05987446,\n",
            "        -0.08374243, -0.08339935, -0.0712539 , -0.07662271, -0.07600835,\n",
            "        -0.07233796, -0.09713576, -0.07474615, -0.06512678, -0.09467216,\n",
            "        -0.07840924, -0.06326141, -0.07638085, -0.08075849, -0.07609792,\n",
            "        -0.09734869, -0.08348099, -0.08651357, -0.07627308, -0.08294801,\n",
            "        -0.07324637, -0.05839477, -0.04872104, -0.07136072, -0.0948989 ,\n",
            "        -0.08410863, -0.05887561, -0.07013092, -0.0776247 , -0.06765635,\n",
            "        -0.09782637, -0.08334076, -0.08315206, -0.08611289, -0.09277927,\n",
            "        -0.07299289, -0.08077321, -0.08238029, -0.08038433, -0.0916817 ,\n",
            "        -0.07808897, -0.1034521 , -0.07976053, -0.08781774, -0.06669569,\n",
            "        -0.08040581, -0.10767824, -0.07275443, -0.10075111],\n",
            "       [ 0.15712945,  0.12071525,  0.12357202,  0.11801771,  0.17550227,\n",
            "         0.16162651,  0.11768264,  0.10376584,  0.15007323,  0.10932583,\n",
            "         0.17282036,  0.1541467 ,  0.1951296 ,  0.17490981,  0.14773517,\n",
            "         0.1535241 ,  0.1235147 ,  0.11386546,  0.14791823,  0.16055165,\n",
            "         0.14761724,  0.18361359,  0.13034763,  0.13674216,  0.15721377,\n",
            "         0.16728955,  0.14631663,  0.11877467,  0.16280823,  0.15436476,\n",
            "         0.17058883,  0.16023935,  0.13401308,  0.1390699 ,  0.15837974,\n",
            "         0.15828137,  0.11967417,  0.10652771,  0.13061001,  0.1599411 ,\n",
            "         0.11244105,  0.14219935,  0.13124144,  0.12030144,  0.12153   ,\n",
            "         0.16390862,  0.15355371,  0.11083061,  0.10418293,  0.16007735,\n",
            "         0.14495428,  0.15928231,  0.13283152,  0.12120901,  0.17544417,\n",
            "         0.15542751,  0.16884017,  0.14931845,  0.13720531,  0.12021659,\n",
            "         0.16659196,  0.16843558,  0.14742379,  0.1396571 ],\n",
            "       [-0.12207128, -0.06854475, -0.06419198, -0.06194886, -0.12000754,\n",
            "        -0.10485853, -0.06893874, -0.07155546, -0.099052  , -0.06069455,\n",
            "        -0.1360043 , -0.13896656, -0.14792318, -0.12681803, -0.11972884,\n",
            "        -0.09451498, -0.07614758, -0.044716  , -0.08833378, -0.12328297,\n",
            "        -0.11276813, -0.14832291, -0.07289606, -0.07022435, -0.10637949,\n",
            "        -0.12551584, -0.09965441, -0.07688715, -0.11128889, -0.10295208,\n",
            "        -0.09959384, -0.10771507, -0.07573838, -0.10354295, -0.11815869,\n",
            "        -0.10314013, -0.07892086, -0.05714327, -0.08723006, -0.11942292,\n",
            "        -0.05095028, -0.11311899, -0.09089813, -0.07113184, -0.07276015,\n",
            "        -0.12401521, -0.10557331, -0.06027474, -0.06228924, -0.0873341 ,\n",
            "        -0.08289015, -0.1091066 , -0.07571172, -0.07642983, -0.13276531,\n",
            "        -0.10849134, -0.09379794, -0.09383953, -0.05767534, -0.08595149,\n",
            "        -0.10357812, -0.09841743, -0.11044855, -0.08442893],\n",
            "       [-0.04671357, -0.04290159, -0.03901739, -0.03760709, -0.05818491,\n",
            "        -0.05537383, -0.04017031, -0.03599232, -0.04346674, -0.0350937 ,\n",
            "        -0.04857617, -0.0458032 , -0.06112676, -0.05471215, -0.04173644,\n",
            "        -0.04156477, -0.03919114, -0.03783883, -0.04585659, -0.04395974,\n",
            "        -0.04362518, -0.05705581, -0.04682521, -0.04997603, -0.05104375,\n",
            "        -0.04578543, -0.04473161, -0.04022802, -0.04654411, -0.04372948,\n",
            "        -0.05985368, -0.05436361, -0.04109929, -0.04377257, -0.04894888,\n",
            "        -0.05429835, -0.03823317, -0.03415982, -0.03927   , -0.04617489,\n",
            "        -0.03872349, -0.04816861, -0.04356958, -0.03575791, -0.04512313,\n",
            "        -0.0513368 , -0.04668464, -0.04423008, -0.03473456, -0.05405851,\n",
            "        -0.04349911, -0.04344673, -0.04417503, -0.04610043, -0.05657006,\n",
            "        -0.04655826, -0.055393  , -0.04511585, -0.04550186, -0.03904247,\n",
            "        -0.04892104, -0.05842485, -0.04139259, -0.04985571],\n",
            "       [ 0.14932511,  0.11472164,  0.11742817,  0.11215018,  0.1667928 ,\n",
            "         0.15359791,  0.11183983,  0.09861538,  0.14261663,  0.10389368,\n",
            "         0.1642361 ,  0.1464953 ,  0.18543849,  0.16622595,  0.14039629,\n",
            "         0.14589808,  0.11738625,  0.10820462,  0.14056862,  0.15257636,\n",
            "         0.14028795,  0.17449783,  0.12386908,  0.12995124,  0.14941224,\n",
            "         0.15897845,  0.13904411,  0.11288133,  0.1547271 ,  0.1466923 ,\n",
            "         0.16211641,  0.15228143,  0.12735315,  0.13216666,  0.15051319,\n",
            "         0.15041272,  0.11372891,  0.10123646,  0.12411799,  0.15199921,\n",
            "         0.10685619,  0.13513877,  0.12472425,  0.11432427,  0.11549636,\n",
            "         0.15577191,  0.14592824,  0.10533082,  0.09901107,  0.15212668,\n",
            "         0.137751  ,  0.1513694 ,  0.1262327 ,  0.11519492,  0.16673152,\n",
            "         0.14770707,  0.16045445,  0.14189707,  0.13038865,  0.1142443 ,\n",
            "         0.15831779,  0.16007678,  0.14010089,  0.13272583],\n",
            "       [-0.10953839, -0.10747918, -0.11523832, -0.11828025, -0.11574991,\n",
            "        -0.13923736, -0.09709877, -0.0707685 , -0.12267563, -0.08684372,\n",
            "        -0.12831852, -0.09643463, -0.15209114, -0.12441799, -0.11965156,\n",
            "        -0.13086731, -0.10581069, -0.1222824 , -0.12803837, -0.12919846,\n",
            "        -0.10355347, -0.12823275, -0.11841204, -0.11868591, -0.1140016 ,\n",
            "        -0.13592756, -0.12437285, -0.08466618, -0.11957141, -0.12705013,\n",
            "        -0.15205021, -0.13366834, -0.11927135, -0.10737219, -0.11967538,\n",
            "        -0.14425363, -0.10385019, -0.09946304, -0.11163211, -0.11276452,\n",
            "        -0.091273  , -0.11506228, -0.09530937, -0.09645661, -0.1073819 ,\n",
            "        -0.11841038, -0.12981551, -0.08376646, -0.07778453, -0.13774551,\n",
            "        -0.14800865, -0.13194252, -0.09792853, -0.08763906, -0.13179362,\n",
            "        -0.13072465, -0.15824667, -0.11883683, -0.12888469, -0.09732954,\n",
            "        -0.14617022, -0.12225959, -0.10735284, -0.11176337],\n",
            "       [ 0.13989541,  0.10747474,  0.1100201 ,  0.10507584,  0.15625268,\n",
            "         0.14390031,  0.1047744 ,  0.09238216,  0.13361286,  0.09733604,\n",
            "         0.15386458,  0.13723848,  0.17372782,  0.15572405,  0.13153237,\n",
            "         0.1366826 ,  0.10996672,  0.10137803,  0.1316963 ,  0.14294145,\n",
            "         0.13142507,  0.16347321,  0.11605385,  0.1217479 ,  0.13996879,\n",
            "         0.14894135,  0.13026941,  0.1057447 ,  0.14494909,  0.13743631,\n",
            "         0.15188177,  0.14266683,  0.11931358,  0.12381535,  0.14100825,\n",
            "         0.14092535,  0.10654982,  0.09484508,  0.11628679,  0.14239783,\n",
            "         0.10010721,  0.12660381,  0.11684499,  0.10710627,  0.1082011 ,\n",
            "         0.1459305 ,  0.13670885,  0.09867509,  0.09275384,  0.14252185,\n",
            "         0.1290577 ,  0.14181208,  0.11826384,  0.10791258,  0.15620128,\n",
            "         0.13838082,  0.1503219 ,  0.13294165,  0.12215532,  0.10703352,\n",
            "         0.14832014,  0.14996018,  0.13125495,  0.12433768],\n",
            "       [-0.14313507, -0.10338338, -0.10578346, -0.10430602, -0.16449257,\n",
            "        -0.13938836, -0.1086229 , -0.08651997, -0.13280082, -0.09692578,\n",
            "        -0.15371732, -0.13364358, -0.16626682, -0.15706413, -0.12991127,\n",
            "        -0.14280016, -0.11535982, -0.09567981, -0.13541729, -0.14257679,\n",
            "        -0.13943319, -0.16108047, -0.10787985, -0.13738109, -0.14675345,\n",
            "        -0.15092339, -0.12876575, -0.11083236, -0.16471977, -0.14092995,\n",
            "        -0.15009302, -0.14179307, -0.10707477, -0.12442036, -0.13653616,\n",
            "        -0.13336168, -0.10385634, -0.1069781 , -0.11165982, -0.1412007 ,\n",
            "        -0.09725602, -0.12448949, -0.12153052, -0.10361785, -0.10524456,\n",
            "        -0.14082333, -0.13174554, -0.0944555 , -0.07869707, -0.14381085,\n",
            "        -0.12897714, -0.14820346, -0.11844734, -0.10838022, -0.15209998,\n",
            "        -0.1406039 , -0.14566198, -0.1315577 , -0.12485666, -0.10192888,\n",
            "        -0.15928855, -0.15989311, -0.13671606, -0.11486461],\n",
            "       [ 0.14912512,  0.11458229,  0.11729006,  0.11202108,  0.1665668 ,\n",
            "         0.15340855,  0.11169864,  0.09848237,  0.14243642,  0.10376411,\n",
            "         0.16401884,  0.1462912 ,  0.18519871,  0.16600332,  0.14021502,\n",
            "         0.14571305,  0.11724091,  0.10808695,  0.14039601,  0.15237967,\n",
            "         0.1400975 ,  0.1742626 ,  0.12372358,  0.12979127,  0.14921369,\n",
            "         0.15877502,  0.13886841,  0.11272997,  0.1545173 ,  0.14650947,\n",
            "         0.1619218 ,  0.15209136,  0.12719973,  0.13199392,  0.15031623,\n",
            "         0.15023382,  0.11358886,  0.10111325,  0.12396686,  0.15179788,\n",
            "         0.10672397,  0.13496379,  0.1245573 ,  0.11418093,  0.11535438,\n",
            "         0.15556665,  0.14574167,  0.10519818,  0.09888534,  0.15194023,\n",
            "         0.13759335,  0.15117778,  0.12607134,  0.11504224,  0.1665135 ,\n",
            "         0.14752085,  0.16026384,  0.14171714,  0.13023318,  0.1141026 ,\n",
            "         0.15811923,  0.15986626,  0.13991619,  0.13255884],\n",
            "       [-0.09539711, -0.0575477 , -0.07399313, -0.06715449, -0.10277749,\n",
            "        -0.08489599, -0.05716022, -0.06004608, -0.08910174, -0.0687428 ,\n",
            "        -0.10400799, -0.09193895, -0.11389234, -0.10322905, -0.08897628,\n",
            "        -0.08832819, -0.0482    , -0.05976412, -0.08631041, -0.09342282,\n",
            "        -0.08770984, -0.10401954, -0.07323484, -0.07683839, -0.08295806,\n",
            "        -0.09742291, -0.09371252, -0.06113611, -0.09411906, -0.09424329,\n",
            "        -0.08756936, -0.0862579 , -0.07818216, -0.07166468, -0.09395029,\n",
            "        -0.0915531 , -0.07028643, -0.05725724, -0.07382895, -0.09167408,\n",
            "        -0.063817  , -0.07919076, -0.07592948, -0.07132398, -0.06241574,\n",
            "        -0.08876558, -0.08477273, -0.05415586, -0.0552149 , -0.09093788,\n",
            "        -0.07298838, -0.09016904, -0.08475649, -0.0604249 , -0.09997981,\n",
            "        -0.08456913, -0.08332867, -0.09676389, -0.07524618, -0.06464894,\n",
            "        -0.09298538, -0.09166558, -0.09003135, -0.06761571]])]\n",
            "del b [array([[0.37060449]]), array([-9.81935492e-04, -3.03921412e-04, -6.30806781e-03,  4.23999567e-03,\n",
            "        2.53278604e-03, -5.12643146e-04, -4.56009302e-04, -8.26856212e-04,\n",
            "        1.17289831e-03, -1.78641933e-04,  1.96580347e-03, -1.47722903e-03,\n",
            "       -2.21668090e-03, -8.04633388e-04,  2.84873973e-03,  2.39690904e-03,\n",
            "       -7.88299092e-04, -9.85695593e-04,  1.06338476e-04, -2.32333382e-03,\n",
            "       -1.04540630e-03,  2.22887781e-04, -3.46948669e-03, -6.48535514e-04,\n",
            "       -4.61118197e-03, -9.41801095e-04,  2.28971396e-03, -3.01068833e-03,\n",
            "        4.69951730e-04, -1.82329131e-04,  1.01828130e-03, -2.20670853e-03,\n",
            "       -4.06955064e-05, -2.27766500e-03, -2.05791306e-03, -9.47293218e-05,\n",
            "       -1.18877187e-03, -3.65666203e-03, -6.95002608e-04,  2.14862884e-03,\n",
            "        2.35385010e-03,  2.37545759e-03, -7.45363771e-04,  2.19717518e-03,\n",
            "       -1.96954765e-03, -1.78064834e-03, -1.52159428e-03,  2.45289247e-03,\n",
            "       -2.71343453e-03,  6.72092811e-04, -1.20534767e-03, -1.97215931e-03,\n",
            "        1.24159483e-03, -6.65051631e-03, -2.44868148e-03,  4.37121472e-04,\n",
            "       -1.06405898e-03, -6.74948978e-04, -1.72696037e-03, -3.65684811e-03,\n",
            "       -7.68495576e-04, -5.59769971e-03,  2.48432141e-03, -4.02769439e-04]), array([-0.01453981, -0.01339286, -0.01257477,  0.00086499, -0.01082878,\n",
            "       -0.00099309, -0.00523112, -0.00268149, -0.00084302, -0.00528021,\n",
            "       -0.01709715,  0.00021135, -0.00795386, -0.00495966, -0.03530809,\n",
            "       -0.00519243,  0.00904227, -0.00121257, -0.00302099, -0.00897707,\n",
            "        0.00266306, -0.02518553,  0.00488565, -0.02951786, -0.0163992 ,\n",
            "       -0.01238327, -0.0204959 , -0.00762158, -0.01934261, -0.02875511,\n",
            "       -0.02341501, -0.02250358, -0.02174875, -0.00112008, -0.02201615,\n",
            "       -0.01953757, -0.00513553,  0.00269285, -0.0181189 , -0.02731789,\n",
            "        0.00364068, -0.02436636, -0.01843553,  0.00267632, -0.02201052,\n",
            "       -0.0187323 , -0.02695217, -0.01917978, -0.02676728, -0.01370962,\n",
            "       -0.00362824,  0.01389978, -0.01898605,  0.01884857, -0.03110024,\n",
            "       -0.01968355, -0.02112418, -0.00946822, -0.01583054, -0.01485549,\n",
            "       -0.01769967, -0.00997812,  0.00613815,  0.01736822]), array([-0.15213781,  0.28167564, -0.18686602, -0.08896916,  0.26768483,\n",
            "       -0.22739079,  0.25078191, -0.2516519 ,  0.26734457, -0.16047128])]\n",
            "type of weight  <class 'numpy.ndarray'>\n",
            "type of bias  <class 'numpy.ndarray'>\n",
            "Completed epoch : 10 \t Error: 1.803934420056193\n",
            "Completed epoch : 11 \t Error: 1.7944868354275765\n",
            "Completed epoch : 12 \t Error: 1.786297689433658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-c69928806e4c>:195: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.weight -= self.learning_rate * del_w\n",
            "<ipython-input-20-c69928806e4c>:196: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.bias -= self.learning_rate * del_b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed epoch : 13 \t Error: 1.7791089429114355\n",
            "Completed epoch : 14 \t Error: 1.7727318055116388\n",
            "Completed epoch : 15 \t Error: 1.767024273282179\n",
            "Completed epoch : 16 \t Error: 1.7618768449789997\n",
            "Completed epoch : 17 \t Error: 1.7572032570414788\n",
            "Completed epoch : 18 \t Error: 1.752934323257828\n",
            "Completed epoch : 19 \t Error: 1.7490137237537489\n",
            "Completed epoch : 20 \t Error: 1.7453950434039194\n",
            "Completed epoch : 21 \t Error: 1.7420396313469044\n",
            "Completed epoch : 22 \t Error: 1.7389150152181816\n",
            "Completed epoch : 23 \t Error: 1.7359937008652953\n",
            "Completed epoch : 24 \t Error: 1.7332522472804304\n",
            "Completed epoch : 25 \t Error: 1.7306705428959681\n",
            "Completed epoch : 26 \t Error: 1.728231232363824\n",
            "Completed epoch : 27 \t Error: 1.7259192578123976\n",
            "Completed epoch : 28 \t Error: 1.7237214884751537\n",
            "Completed epoch : 29 \t Error: 1.7216264193638682\n",
            "Completed epoch : 30 \t Error: 1.7196239244276534\n",
            "Completed epoch : 31 \t Error: 1.7177050530741191\n",
            "Completed epoch : 32 \t Error: 1.7158618614550807\n",
            "Completed epoch : 33 \t Error: 1.7140872718083398\n",
            "Completed epoch : 34 \t Error: 1.7123749545790556\n",
            "Completed epoch : 35 \t Error: 1.7107192291416724\n",
            "Completed epoch : 36 \t Error: 1.7091149797918672\n",
            "Completed epoch : 37 \t Error: 1.7075575843389257\n",
            "Completed epoch : 38 \t Error: 1.7060428531470748\n",
            "Completed epoch : 39 \t Error: 1.7045669768828353\n",
            "Completed epoch : 40 \t Error: 1.7031264815492875\n",
            "Completed epoch : 41 \t Error: 1.7017181896461686\n",
            "Completed epoch : 42 \t Error: 1.7003391865013213\n",
            "Completed epoch : 43 \t Error: 1.698986790985207\n",
            "Completed epoch : 44 \t Error: 1.697658529954601\n",
            "Completed epoch : 45 \t Error: 1.6963521158806993\n",
            "Completed epoch : 46 \t Error: 1.6950654272059134\n",
            "Completed epoch : 47 \t Error: 1.693796491046595\n",
            "Completed epoch : 48 \t Error: 1.6925434679190041\n",
            "Completed epoch : 49 \t Error: 1.6913046382154604\n",
            "50 th iteration\n",
            "del w [array([[0.41179541]]), array([[ 0.        ,  0.        ,  0.        , ...,  0.00098027,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00080992,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00025751,\n",
            "         0.        ,  0.        ],\n",
            "       ...,\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00038196,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ...,  0.00054524,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.0002756 ,\n",
            "         0.        ,  0.        ]]), array([[-0.00928537,  0.00174294, -0.00618173, ..., -0.00431432,\n",
            "        -0.01114277, -0.00649834],\n",
            "       [-0.00022711, -0.00272748, -0.00062657, ..., -0.00094048,\n",
            "        -0.00217118,  0.00060654],\n",
            "       [-0.00195862,  0.00043402,  0.00160721, ...,  0.00055285,\n",
            "        -0.00453267,  0.00047432],\n",
            "       ...,\n",
            "       [-0.00057543, -0.0043298 ,  0.00361607, ...,  0.00155851,\n",
            "         0.00401523,  0.00147321],\n",
            "       [ 0.00786873, -0.00048867,  0.00639983, ...,  0.00321958,\n",
            "         0.00624225,  0.0064584 ],\n",
            "       [ 0.00219374,  0.00168539,  0.00690485, ...,  0.00510559,\n",
            "         0.00161345,  0.00681296]]), array([[ 6.80073446e-03, -4.16059712e-02, -2.26385494e-02,\n",
            "        -1.77090731e-02, -3.00425833e-02, -4.73796966e-02,\n",
            "        -5.13988215e-02, -4.52131463e-02, -6.96643004e-03,\n",
            "        -5.70992679e-02, -9.82381857e-05, -2.01990153e-02,\n",
            "         1.56194371e-02, -3.61840666e-02,  2.94629051e-02,\n",
            "        -3.18273330e-02, -5.22146889e-02, -4.26791979e-02,\n",
            "        -2.57871289e-02,  6.14863329e-03, -2.00692742e-02,\n",
            "        -2.38937489e-02, -1.40941096e-02, -3.59295666e-02,\n",
            "        -1.81285902e-02,  7.94242136e-03, -6.16831808e-03,\n",
            "        -4.66284963e-02, -1.27292863e-02, -7.97198652e-03,\n",
            "        -2.57618095e-02, -3.65678479e-02, -6.05559949e-02,\n",
            "         1.67045199e-03, -2.52410605e-02, -1.39690939e-02,\n",
            "        -1.67292259e-02,  8.95301214e-03, -7.19517122e-03,\n",
            "        -1.00994041e-02, -4.49007824e-02,  1.89537185e-02,\n",
            "        -2.77554676e-02, -4.27799465e-02, -4.59641777e-02,\n",
            "        -1.24611804e-02, -2.02798694e-02, -3.34602922e-02,\n",
            "        -5.37897248e-02, -2.77139402e-02, -5.20159534e-04,\n",
            "         7.88057231e-03, -2.79099306e-02, -4.73351071e-02,\n",
            "         5.54859241e-04,  1.57909579e-04, -1.34118010e-02,\n",
            "        -1.98516395e-02, -3.00313615e-02, -7.50370816e-03,\n",
            "         1.11420537e-02, -6.57443384e-02, -3.76158986e-02,\n",
            "        -7.30963057e-02],\n",
            "       [ 3.54319484e-02,  2.78847393e-02,  2.76494134e-02,\n",
            "         2.53550154e-02,  4.00498497e-02,  3.54348618e-02,\n",
            "         2.56797803e-02,  2.30466183e-02,  3.30440097e-02,\n",
            "         2.48609933e-02,  3.95042665e-02,  3.51988075e-02,\n",
            "         4.37444881e-02,  3.94165051e-02,  3.50580451e-02,\n",
            "         3.27701030e-02,  2.71187235e-02,  2.48108334e-02,\n",
            "         3.33096328e-02,  3.61659128e-02,  3.24716276e-02,\n",
            "         4.21380492e-02,  2.75406644e-02,  3.20243175e-02,\n",
            "         3.50029750e-02,  3.77596578e-02,  3.38941425e-02,\n",
            "         2.73239621e-02,  3.80559522e-02,  3.52711909e-02,\n",
            "         3.87594298e-02,  3.69702151e-02,  2.98969219e-02,\n",
            "         3.12267802e-02,  3.67285662e-02,  3.64977933e-02,\n",
            "         2.64139063e-02,  2.28758961e-02,  2.99987226e-02,\n",
            "         3.70133634e-02,  2.35516964e-02,  3.25591139e-02,\n",
            "         2.93215619e-02,  2.66747690e-02,  2.84396001e-02,\n",
            "         3.76573651e-02,  3.51693618e-02,  2.52242025e-02,\n",
            "         2.43258505e-02,  3.57444891e-02,  3.12029319e-02,\n",
            "         3.51655471e-02,  3.00882844e-02,  2.59619414e-02,\n",
            "         4.01047456e-02,  3.54394320e-02,  3.76586915e-02,\n",
            "         3.34165140e-02,  3.04419912e-02,  2.77861893e-02,\n",
            "         3.73960435e-02,  3.77679269e-02,  3.33614183e-02,\n",
            "         3.03604648e-02],\n",
            "       [-3.42986978e-02, -8.55649920e-03,  2.16149459e-02,\n",
            "         3.08218405e-02, -5.71704746e-02,  1.91090526e-04,\n",
            "         1.29387409e-02, -2.42016163e-03, -1.23450008e-02,\n",
            "         3.83178619e-03, -6.17335673e-02, -9.20786136e-02,\n",
            "        -6.45493395e-02, -4.82632728e-02, -7.06237550e-02,\n",
            "         3.35408515e-02, -9.79513354e-03,  4.12697135e-02,\n",
            "        -1.66374146e-02, -4.15686066e-02, -2.71034932e-02,\n",
            "        -6.09704870e-02,  3.93578001e-02,  4.95341634e-03,\n",
            "        -5.00265385e-03, -4.45081038e-02, -3.26846796e-02,\n",
            "        -2.63443153e-02, -5.54910013e-02, -1.48089362e-02,\n",
            "         4.91939888e-04, -3.20139310e-02,  3.29500012e-02,\n",
            "        -3.90156722e-02, -5.02526496e-02, -2.19349328e-02,\n",
            "        -1.93359748e-03,  2.12892528e-02, -1.51925800e-02,\n",
            "        -5.28448265e-02,  4.77274133e-02, -3.96706541e-02,\n",
            "         1.73913082e-03, -1.83830865e-03, -1.21804987e-02,\n",
            "        -6.79388972e-02, -2.60614051e-02,  3.94202143e-03,\n",
            "        -4.03910013e-04,  8.73426514e-03,  3.34457811e-02,\n",
            "        -4.68164614e-02,  4.18300393e-04,  3.04343821e-03,\n",
            "        -4.22777753e-02, -3.19174665e-02,  1.03144060e-02,\n",
            "        -4.40552496e-03,  3.61556240e-02, -3.46604375e-02,\n",
            "        -1.48416255e-02, -1.06913732e-02, -5.49713523e-02,\n",
            "        -7.77877636e-03],\n",
            "       [-1.71937292e-02, -2.73016774e-02, -1.74836616e-02,\n",
            "        -2.33622993e-02, -2.83054046e-02, -3.40404412e-02,\n",
            "        -3.05215770e-02, -2.41043475e-02, -1.49125652e-02,\n",
            "        -2.54096307e-02, -1.63552724e-02, -2.14734655e-02,\n",
            "        -1.85600322e-02, -2.95428652e-02, -1.24323272e-02,\n",
            "        -2.19482932e-02, -2.49557200e-02, -2.45117350e-02,\n",
            "        -2.50073306e-02, -1.60121844e-02, -2.18502092e-02,\n",
            "        -2.75131395e-02, -2.35650798e-02, -3.38758109e-02,\n",
            "        -2.34688969e-02, -1.51629467e-02, -2.13866460e-02,\n",
            "        -2.52531632e-02, -1.98284158e-02, -1.84919016e-02,\n",
            "        -3.01394968e-02, -3.35393733e-02, -2.79868600e-02,\n",
            "        -1.53188710e-02, -2.39451598e-02, -2.92806534e-02,\n",
            "        -2.15375930e-02, -1.47207056e-02, -1.51751066e-02,\n",
            "        -1.61216775e-02, -2.37111450e-02, -2.05951489e-02,\n",
            "        -2.53836981e-02, -1.89999827e-02, -3.27468793e-02,\n",
            "        -1.92550915e-02, -2.41855443e-02, -2.57860589e-02,\n",
            "        -2.14823126e-02, -2.77799876e-02, -1.62723297e-02,\n",
            "        -9.67821461e-03, -2.22680775e-02, -3.13201787e-02,\n",
            "        -2.13336661e-02, -1.71188353e-02, -2.20001087e-02,\n",
            "        -2.10007380e-02, -2.13444170e-02, -1.81004850e-02,\n",
            "        -1.68732100e-02, -3.56883855e-02, -2.03303421e-02,\n",
            "        -3.29649156e-02],\n",
            "       [ 3.48569278e-02,  2.74333545e-02,  2.71940207e-02,\n",
            "         2.49361525e-02,  3.94073119e-02,  3.48591323e-02,\n",
            "         2.52623669e-02,  2.26746213e-02,  3.25052063e-02,\n",
            "         2.44587103e-02,  3.88663755e-02,  3.46390007e-02,\n",
            "         4.30364908e-02,  3.87829819e-02,  3.44926840e-02,\n",
            "         3.22324853e-02,  2.66815706e-02,  2.44010856e-02,\n",
            "         3.27695350e-02,  3.55802370e-02,  3.19470915e-02,\n",
            "         4.14604809e-02,  2.70841612e-02,  3.15054200e-02,\n",
            "         3.44338752e-02,  3.71474638e-02,  3.33444331e-02,\n",
            "         2.68859284e-02,  3.74441132e-02,  3.46970048e-02,\n",
            "         3.81277632e-02,  3.63739340e-02,  2.94068264e-02,\n",
            "         3.07223656e-02,  3.61372296e-02,  3.59042410e-02,\n",
            "         2.59841241e-02,  2.24983867e-02,  2.95096069e-02,\n",
            "         3.64157781e-02,  2.31625994e-02,  3.20314686e-02,\n",
            "         2.88447941e-02,  2.62410489e-02,  2.79813433e-02,\n",
            "         3.70521030e-02,  3.46000788e-02,  2.48134339e-02,\n",
            "         2.39317057e-02,  3.51606078e-02,  3.06868990e-02,\n",
            "         3.45955804e-02,  2.95979733e-02,  2.55420634e-02,\n",
            "         3.94552599e-02,  3.48641642e-02,  3.70411448e-02,\n",
            "         3.28714425e-02,  2.99402787e-02,  2.73365024e-02,\n",
            "         3.67858781e-02,  3.71592979e-02,  3.28271099e-02,\n",
            "         2.98716754e-02],\n",
            "       [-2.17464253e-02, -1.73040973e-02, -4.58572215e-02,\n",
            "        -5.53855758e-02,  2.02331362e-02, -2.09384387e-02,\n",
            "        -1.85188625e-02,  7.36070269e-03, -3.97506727e-02,\n",
            "         9.42010643e-03, -1.79592257e-02,  3.29695038e-02,\n",
            "        -3.54054586e-02,  1.10741622e-02, -2.47117941e-02,\n",
            "        -5.46912528e-02, -1.05060069e-02, -5.67813460e-02,\n",
            "        -1.74740827e-02, -3.12255411e-02, -6.76328967e-03,\n",
            "         6.28784047e-03, -6.84394384e-02,  2.17932190e-03,\n",
            "        -2.95684164e-02, -3.34746671e-02, -1.85850908e-02,\n",
            "         1.08343994e-02,  6.96630980e-03, -2.56149311e-02,\n",
            "        -3.74668659e-02, -3.93068127e-03, -4.30916175e-02,\n",
            "        -1.61903417e-02,  3.85404261e-03, -3.26183372e-02,\n",
            "        -2.67888543e-02, -5.18748854e-02, -2.85696902e-02,\n",
            "        -1.63176119e-02, -4.81344316e-02, -2.97997113e-02,\n",
            "        -1.87132198e-02, -1.42712019e-02, -3.06863537e-03,\n",
            "        -1.73653349e-03, -2.87891930e-02, -2.68484946e-02,\n",
            "        -1.03647077e-02, -4.64639939e-02, -8.16638660e-02,\n",
            "        -3.44597894e-02, -1.90288436e-02, -2.60260131e-03,\n",
            "        -2.37837269e-02, -3.17500227e-02, -7.50867075e-02,\n",
            "        -2.36597943e-02, -6.22630796e-02, -1.73139986e-02,\n",
            "        -5.75318218e-02,  1.65706216e-02,  2.82678770e-02,\n",
            "         6.27524704e-03],\n",
            "       [ 3.38431834e-02,  2.66347196e-02,  2.64059685e-02,\n",
            "         2.42132443e-02,  3.82575992e-02,  3.38448580e-02,\n",
            "         2.45269772e-02,  2.20138044e-02,  3.15603630e-02,\n",
            "         2.37474583e-02,  3.77347306e-02,  3.36273620e-02,\n",
            "         4.17839506e-02,  3.76519528e-02,  3.34877386e-02,\n",
            "         3.12951301e-02,  2.59029902e-02,  2.36940458e-02,\n",
            "         3.18159857e-02,  3.45442413e-02,  3.10163937e-02,\n",
            "         4.02515831e-02,  2.63003965e-02,  3.05879554e-02,\n",
            "         3.34311647e-02,  3.60662759e-02,  3.23745442e-02,\n",
            "         2.61013297e-02,  3.63513141e-02,  3.36882851e-02,\n",
            "         3.70193073e-02,  3.53142516e-02,  2.85535752e-02,\n",
            "         2.98268823e-02,  3.50843650e-02,  3.48614104e-02,\n",
            "         2.52283361e-02,  2.18450735e-02,  2.86525572e-02,\n",
            "         3.53554238e-02,  2.24911327e-02,  3.10987745e-02,\n",
            "         2.80055453e-02,  2.54787580e-02,  2.71657532e-02,\n",
            "         3.59719845e-02,  3.35915800e-02,  2.40926036e-02,\n",
            "         2.32357756e-02,  3.41390648e-02,  2.97966208e-02,\n",
            "         3.35886862e-02,  2.87384407e-02,  2.47978052e-02,\n",
            "         3.83066082e-02,  3.38493852e-02,  3.59651064e-02,\n",
            "         3.19166435e-02,  2.90716855e-02,  2.65417892e-02,\n",
            "         3.57155304e-02,  3.60756210e-02,  3.18699388e-02,\n",
            "         2.90010365e-02],\n",
            "       [-3.06571809e-02, -8.82355895e-03, -1.56341229e-02,\n",
            "        -2.01163223e-02, -3.32505996e-02, -2.40130971e-02,\n",
            "        -1.84868200e-02, -1.22684264e-02, -2.54739022e-02,\n",
            "        -1.12193404e-02, -1.98851435e-02, -1.05552039e-02,\n",
            "        -2.11596307e-02, -2.61864418e-02, -2.20810388e-02,\n",
            "        -3.72358628e-02, -2.15847479e-02, -7.82430890e-03,\n",
            "        -2.45804457e-02, -2.61668892e-02, -2.65552738e-02,\n",
            "        -2.78799609e-02, -1.75187230e-02, -4.46382568e-02,\n",
            "        -3.97624776e-02, -2.80047090e-02, -1.77325734e-02,\n",
            "        -1.28804000e-02, -3.90770721e-02, -3.74976025e-02,\n",
            "        -3.47363378e-02, -2.50964968e-02, -4.72726268e-03,\n",
            "        -2.80358234e-02, -1.85435087e-02, -1.52119125e-02,\n",
            "        -1.97141139e-02, -3.60938915e-02, -2.29888064e-02,\n",
            "        -2.04128317e-02, -1.51349543e-02, -2.44198606e-02,\n",
            "        -2.56143117e-02, -6.36192951e-03, -1.25211021e-02,\n",
            "        -1.95519781e-02, -2.08958839e-02, -7.10562350e-03,\n",
            "         2.10730152e-03, -2.48013880e-02, -3.67097787e-02,\n",
            "        -2.39928275e-02, -1.93507624e-02, -1.78980113e-02,\n",
            "        -3.28015282e-02, -3.17336261e-02, -2.66949135e-02,\n",
            "        -2.30020834e-02, -2.09101033e-02, -1.03694324e-02,\n",
            "        -4.10003968e-02, -3.60087344e-02, -1.90412325e-02,\n",
            "        -7.38241606e-03],\n",
            "       [ 3.44345088e-02,  2.70992352e-02,  2.68748467e-02,\n",
            "         2.46477599e-02,  3.89161194e-02,  3.44373425e-02,\n",
            "         2.49572426e-02,  2.23937462e-02,  3.21165645e-02,\n",
            "         2.41567595e-02,  3.83905807e-02,  3.41987904e-02,\n",
            "         4.25141440e-02,  3.83010273e-02,  3.40719668e-02,\n",
            "         3.18531000e-02,  2.63550583e-02,  2.41182494e-02,\n",
            "         3.23719183e-02,  3.51493202e-02,  3.15551560e-02,\n",
            "         4.09465523e-02,  2.67735429e-02,  3.11208031e-02,\n",
            "         3.40195627e-02,  3.66985569e-02,  3.29388867e-02,\n",
            "         2.65496341e-02,  3.69800208e-02,  3.42797235e-02,\n",
            "         3.76713411e-02,  3.59270404e-02,  2.90575706e-02,\n",
            "         3.03475122e-02,  3.56896703e-02,  3.54717519e-02,\n",
            "         2.56724728e-02,  2.22389723e-02,  2.91557771e-02,\n",
            "         3.59701088e-02,  2.28933754e-02,  3.16447591e-02,\n",
            "         2.84955789e-02,  2.59222276e-02,  2.76365599e-02,\n",
            "         3.65936464e-02,  3.41798768e-02,  2.45156572e-02,\n",
            "         2.36387773e-02,  3.47422402e-02,  3.03353862e-02,\n",
            "         3.41777132e-02,  2.92411451e-02,  2.52286506e-02,\n",
            "         3.89757036e-02,  3.44435847e-02,  3.66068111e-02,\n",
            "         3.24758376e-02,  2.95908820e-02,  2.70039520e-02,\n",
            "         3.63494216e-02,  3.66989916e-02,  3.24144177e-02,\n",
            "         2.95009177e-02],\n",
            "       [-4.14712695e-02, -5.46024437e-03, -2.81256398e-02,\n",
            "        -1.34007421e-02, -2.80949543e-02, -1.23956116e-02,\n",
            "         5.56097306e-03, -1.34834110e-02, -2.97775724e-02,\n",
            "        -1.67475752e-02, -3.84645062e-02, -2.63271661e-02,\n",
            "        -4.70240496e-02, -2.50499827e-02, -3.67244244e-02,\n",
            "        -1.59889282e-02,  1.29979546e-02, -6.49733997e-03,\n",
            "        -2.07806693e-02, -3.26151234e-02, -2.46487287e-02,\n",
            "        -3.08271698e-02, -2.34392144e-02, -1.79275999e-02,\n",
            "        -2.09565427e-02, -3.44639490e-02, -3.59946986e-02,\n",
            "        -6.58887883e-03, -2.86719347e-02, -3.35508463e-02,\n",
            "        -2.39652713e-02, -1.34371109e-02, -1.35031603e-02,\n",
            "        -2.52332840e-02, -2.95114952e-02, -2.97202668e-02,\n",
            "        -1.65954548e-02, -1.70111110e-02, -2.81953094e-02,\n",
            "        -2.89583226e-02, -7.94490375e-03, -3.18024599e-02,\n",
            "        -1.89399137e-02, -2.00654343e-02, -4.74196324e-03,\n",
            "        -2.63314182e-02, -1.73290018e-02, -9.38744943e-03,\n",
            "        -1.11987556e-02, -2.17613572e-02, -2.03014852e-02,\n",
            "        -3.04608063e-02, -2.95265297e-02, -5.41800056e-03,\n",
            "        -3.72004799e-02, -2.62345250e-02, -2.03926291e-02,\n",
            "        -3.87606574e-02, -2.06515001e-02, -2.07203712e-02,\n",
            "        -2.71418731e-02, -1.61396276e-02, -2.67819362e-02,\n",
            "        -3.78692767e-03]])]\n",
            "del b [array([[0.18232934]]), array([-2.17481031e-03,  3.48445008e-04, -2.15621471e-03, -1.66488743e-03,\n",
            "        5.62072201e-04,  1.14436457e-03,  3.58391866e-04, -8.82563951e-04,\n",
            "        9.76233774e-04, -6.06499804e-04,  1.69547656e-03, -1.46117318e-04,\n",
            "       -7.69915683e-04, -4.84743158e-04,  7.17692301e-03,  5.91429519e-04,\n",
            "       -6.06864001e-04,  1.51742418e-03, -3.53591617e-03,  6.99002784e-04,\n",
            "       -1.89934236e-04,  1.13928476e-04, -2.06975181e-04,  7.88568586e-04,\n",
            "       -1.15285575e-03, -1.60100293e-03,  9.43152857e-04, -9.75574120e-04,\n",
            "        6.02644311e-04, -1.69194563e-04,  8.79254551e-04, -1.17177941e-03,\n",
            "       -4.71686770e-04, -1.28283233e-03, -6.93130409e-04,  5.74383036e-04,\n",
            "       -1.68010491e-03,  1.50645403e-03,  1.10790075e-04,  1.36295976e-04,\n",
            "        3.47558004e-03,  8.49245202e-04,  5.15434950e-04,  6.94148948e-04,\n",
            "        9.33396567e-04,  2.55726910e-05, -3.22604709e-04, -1.62627149e-03,\n",
            "        9.97479148e-04,  3.38913712e-04, -5.67861963e-04,  2.67806199e-04,\n",
            "        9.11760891e-04, -4.98631618e-04,  6.33118193e-04, -4.74224314e-04,\n",
            "        1.12795734e-03, -2.73655846e-04, -1.20841066e-03, -1.39577200e-03,\n",
            "       -1.04332116e-04, -1.87357287e-03, -2.38850949e-04, -2.73993742e-04]), array([-0.00675233, -0.00599809, -0.00549977, -0.00353468, -0.00196314,\n",
            "       -0.00238283, -0.00572112, -0.0042958 , -0.002622  , -0.00495299,\n",
            "       -0.00449571,  0.00051473,  0.0012389 , -0.00350848, -0.00832408,\n",
            "       -0.0035053 , -0.00063944, -0.00430545, -0.00357272, -0.00506108,\n",
            "       -0.00223561, -0.00598125, -0.00237934, -0.0090268 , -0.00652126,\n",
            "       -0.00475873, -0.00702744, -0.00437939, -0.00581483, -0.00918826,\n",
            "       -0.00787792, -0.00688192, -0.00794   , -0.00246236, -0.00713988,\n",
            "       -0.00662134, -0.00280809, -0.00134013, -0.00705138, -0.00675033,\n",
            "       -0.00398349, -0.00874338, -0.00583604, -0.00137254, -0.00752123,\n",
            "       -0.00438474, -0.00858218, -0.00702107, -0.0083938 , -0.00523344,\n",
            "       -0.00332816,  0.00249219, -0.00625809,  0.00148593, -0.0075165 ,\n",
            "       -0.00643459, -0.00585225, -0.00521416, -0.00590719, -0.00527932,\n",
            "       -0.00631537, -0.00202109, -0.00020021,  0.00111884]), array([-0.03173538,  0.06170034, -0.02467109, -0.0418022 ,  0.06069735,\n",
            "       -0.04972696,  0.05893178, -0.04729974,  0.05996529, -0.04605939])]\n",
            "type of weight  <class 'numpy.ndarray'>\n",
            "type of bias  <class 'numpy.ndarray'>\n",
            "Completed epoch : 50 \t Error: 1.6900783901988283\n",
            "Completed epoch : 51 \t Error: 1.6888632093177989\n",
            "Completed epoch : 52 \t Error: 1.6876576686741394\n",
            "Completed epoch : 53 \t Error: 1.6864604204971723\n",
            "Completed epoch : 54 \t Error: 1.6852701885010262\n",
            "Completed epoch : 55 \t Error: 1.6840857610173483\n",
            "Completed epoch : 56 \t Error: 1.6829059848106958\n",
            "Completed epoch : 57 \t Error: 1.6817297594961844\n",
            "Completed epoch : 58 \t Error: 1.6805560324894941\n",
            "Completed epoch : 59 \t Error: 1.6793837944283574\n",
            "Completed epoch : 60 \t Error: 1.678212075012365\n",
            "Completed epoch : 61 \t Error: 1.677039939214578\n",
            "Completed epoch : 62 \t Error: 1.6758664838241497\n",
            "Completed epoch : 63 \t Error: 1.6746908342841091\n",
            "Completed epoch : 64 \t Error: 1.6735121417927423\n",
            "Completed epoch : 65 \t Error: 1.672329580640732\n",
            "Completed epoch : 66 \t Error: 1.6711423457594279\n",
            "Completed epoch : 67 \t Error: 1.6699496504584779\n",
            "Completed epoch : 68 \t Error: 1.6687507243334736\n",
            "Completed epoch : 69 \t Error: 1.6675448113264628\n",
            "Completed epoch : 70 \t Error: 1.6663311679240447\n",
            "Completed epoch : 71 \t Error: 1.6651090614794408\n",
            "Completed epoch : 72 \t Error: 1.6638777686464175\n",
            "Completed epoch : 73 \t Error: 1.6626365739142037\n",
            "Completed epoch : 74 \t Error: 1.6613847682337262\n",
            "Completed epoch : 75 \t Error: 1.6601216477264746\n",
            "Completed epoch : 76 \t Error: 1.658846512468243\n",
            "Completed epoch : 77 \t Error: 1.6575586653407766\n",
            "Completed epoch : 78 \t Error: 1.6562574109450832\n",
            "Completed epoch : 79 \t Error: 1.6549420545708269\n",
            "Completed epoch : 80 \t Error: 1.6536119012167707\n",
            "Completed epoch : 81 \t Error: 1.652266254657793\n",
            "Completed epoch : 82 \t Error: 1.6509044165544502\n",
            "Completed epoch : 83 \t Error: 1.6495256856014913\n",
            "Completed epoch : 84 \t Error: 1.648129356712125\n",
            "Completed epoch : 85 \t Error: 1.6467147202351928\n",
            "Completed epoch : 86 \t Error: 1.6452810612027282\n",
            "Completed epoch : 87 \t Error: 1.6438276586056706\n",
            "Completed epoch : 88 \t Error: 1.6423537846958105\n",
            "Completed epoch : 89 \t Error: 1.6408587043122693\n",
            "Completed epoch : 90 \t Error: 1.6393416742310798\n",
            "Completed epoch : 91 \t Error: 1.6378019425366592\n",
            "Completed epoch : 92 \t Error: 1.636238748014171\n",
            "Completed epoch : 93 \t Error: 1.6346513195620027\n",
            "Completed epoch : 94 \t Error: 1.6330388756237622\n",
            "Completed epoch : 95 \t Error: 1.6314006236393954\n",
            "Completed epoch : 96 \t Error: 1.6297357595152253\n",
            "Completed epoch : 97 \t Error: 1.6280434671128798\n",
            "Completed epoch : 98 \t Error: 1.6263229177572616\n",
            "Completed epoch : 99 \t Error: 1.624573269763906\n",
            "100 th iteration\n",
            "del w [array([[0.7770797]]), array([[ 0.        ,  0.        ,  0.        , ...,  0.0010006 ,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00117986,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00034231,\n",
            "         0.        ,  0.        ],\n",
            "       ...,\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00035006,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ...,  0.00070801,\n",
            "         0.        ,  0.        ],\n",
            "       [ 0.        ,  0.        ,  0.        , ..., -0.00022015,\n",
            "         0.        ,  0.        ]]), array([[-0.00742938,  0.00861858, -0.010088  , ..., -0.00578686,\n",
            "        -0.0156205 , -0.01121848],\n",
            "       [-0.00059742, -0.00091735,  0.00386107, ...,  0.00351844,\n",
            "         0.00115596,  0.00566785],\n",
            "       [-0.00542628,  0.00685675,  0.00382532, ...,  0.00369971,\n",
            "        -0.00701895,  0.00186012],\n",
            "       ...,\n",
            "       [-0.0021033 , -0.00354093,  0.01420007, ...,  0.00925169,\n",
            "         0.01056061,  0.01268516],\n",
            "       [ 0.01106877, -0.00469667,  0.01566241, ...,  0.0110093 ,\n",
            "         0.01635864,  0.01753454],\n",
            "       [-0.00279996,  0.00370243,  0.01570373, ...,  0.01241244,\n",
            "         0.00583596,  0.01637208]]), array([[ 0.05123047, -0.05635233, -0.01665579, -0.02134599, -0.02132356,\n",
            "        -0.07930301, -0.09313902, -0.07771793,  0.02742377, -0.11208434,\n",
            "         0.0337324 , -0.02071554,  0.08188129, -0.04340623,  0.08971582,\n",
            "        -0.04581437, -0.08000788, -0.0658161 , -0.02424635,  0.04807134,\n",
            "        -0.02880334, -0.01029912,  0.00426219, -0.06952809,  0.01318152,\n",
            "         0.05202604,  0.00056958, -0.07244936,  0.00537906,  0.00885397,\n",
            "        -0.0120207 , -0.05195409, -0.1010205 ,  0.04244465, -0.02390101,\n",
            "        -0.008422  , -0.0215807 ,  0.04201698,  0.02389915,  0.03022216,\n",
            "        -0.05215044,  0.05643331, -0.03771679, -0.06316364, -0.08365116,\n",
            "         0.02422646, -0.00785658, -0.0272483 , -0.06546431, -0.01344753,\n",
            "         0.03744749,  0.05759308, -0.02184346, -0.06582054,  0.04440758,\n",
            "         0.03746132,  0.03278648, -0.01227008, -0.01881877,  0.01893257,\n",
            "         0.0604602 , -0.10684212, -0.07001188, -0.1253163 ],\n",
            "       [ 0.01724618,  0.0138265 ,  0.01344139,  0.0120554 ,  0.01981012,\n",
            "         0.01692115,  0.01221784,  0.01148054,  0.01611303,  0.01239283,\n",
            "         0.01959132,  0.01758688,  0.02129632,  0.01951252,  0.01768768,\n",
            "         0.01519017,  0.01336568,  0.01187535,  0.01659212,  0.01773839,\n",
            "         0.01586118,  0.0209547 ,  0.01297668,  0.01596462,  0.01681699,\n",
            "         0.01864809,  0.01712611,  0.01387136,  0.01920615,  0.01740386,\n",
            "         0.01899543,  0.01837597,  0.01416818,  0.01570419,  0.01834883,\n",
            "         0.01835467,  0.01277427,  0.01110091,  0.01497939,  0.01844714,\n",
            "         0.01098293,  0.0161119 ,  0.0141694 ,  0.01316457,  0.01424558,\n",
            "         0.01881303,  0.01733479,  0.01244257,  0.01219677,  0.01726482,\n",
            "         0.01469044,  0.01739472,  0.01471347,  0.01257798,  0.01992278,\n",
            "         0.01771324,  0.01807874,  0.01634874,  0.01439177,  0.01412303,\n",
            "         0.01815415,  0.01849492,  0.01667687,  0.01474529],\n",
            "       [-0.01058206,  0.00494143,  0.05572841,  0.07362154, -0.07822961,\n",
            "         0.03498104,  0.05138384,  0.01286022, -0.00094724,  0.02634059,\n",
            "        -0.06949842, -0.12443564, -0.07587806, -0.05640205, -0.09216686,\n",
            "         0.0988756 , -0.00364398,  0.0846929 , -0.01883477, -0.0313362 ,\n",
            "        -0.01719962, -0.06616379,  0.09799572,  0.0206041 ,  0.0309684 ,\n",
            "        -0.04155484, -0.04213706, -0.03254066, -0.08107887, -0.0003469 ,\n",
            "         0.02436552, -0.02980646,  0.09624852, -0.05043256, -0.0539765 ,\n",
            "        -0.0160336 ,  0.02428026,  0.04742065, -0.00633052, -0.06628605,\n",
            "         0.1019947 , -0.03428686,  0.0392807 ,  0.01263478, -0.00478639,\n",
            "        -0.09394155, -0.01627918,  0.02126066,  0.01645294,  0.04273273,\n",
            "         0.08892029, -0.05905049,  0.02180214,  0.02368629, -0.04149335,\n",
            "        -0.03668896,  0.04127265,  0.01540279,  0.08638429, -0.04636633,\n",
            "         0.00233579, -0.00632755, -0.07162351,  0.00415966],\n",
            "       [ 0.00238039, -0.02482875, -0.00494606, -0.0198543 , -0.01461598,\n",
            "        -0.0304449 , -0.03705013, -0.02451875,  0.00456356, -0.03203788,\n",
            "         0.00386646, -0.01209621,  0.01244054, -0.02083986,  0.00986637,\n",
            "        -0.01826206, -0.0259979 , -0.02402207, -0.01642657,  0.00155255,\n",
            "        -0.01445095, -0.01206679, -0.00932235, -0.03217213, -0.0068131 ,\n",
            "         0.00548262, -0.00868408, -0.02364562, -0.00509506, -0.00422514,\n",
            "        -0.01385714, -0.02818616, -0.03118933,  0.00502357, -0.01286347,\n",
            "        -0.01658843, -0.01642814, -0.00051979,  0.00170833,  0.00348205,\n",
            "        -0.02028194, -0.00127373, -0.01931281, -0.01607377, -0.0350738 ,\n",
            "         0.00112334, -0.0138954 , -0.01659635, -0.01903108, -0.01442876,\n",
            "         0.00332799,  0.01447355, -0.01203032, -0.02994754,  0.00378898,\n",
            "         0.00396801,  0.00152463, -0.00892364, -0.00877085, -0.00483038,\n",
            "         0.00541919, -0.03213306, -0.01612984, -0.03595763],\n",
            "       [ 0.01701994,  0.01364966,  0.01325897,  0.01188988,  0.01956546,\n",
            "         0.01670236,  0.01205865,  0.01133577,  0.01590103,  0.01223633,\n",
            "         0.01934205,  0.017376  ,  0.02102262,  0.01926998,  0.01746358,\n",
            "         0.01498361,  0.01319814,  0.01171298,  0.01638067,  0.01750879,\n",
            "         0.01565949,  0.02069226,  0.01279362,  0.01576226,  0.01659436,\n",
            "         0.01840699,  0.01690834,  0.01370042,  0.01896753,  0.01717773,\n",
            "         0.01874682,  0.01814538,  0.01397692,  0.01550439,  0.01811902,\n",
            "         0.01811801,  0.01260717,  0.01094816,  0.01478338,  0.01821268,\n",
            "         0.01082947,  0.01590345,  0.01398308,  0.01299466,  0.01406772,\n",
            "         0.0185785 ,  0.01711233,  0.01227861,  0.01203947,  0.01703502,\n",
            "         0.01448505,  0.01717075,  0.01452028,  0.01241681,  0.01966655,\n",
            "         0.01748496,  0.01783465,  0.01613459,  0.01419327,  0.01394324,\n",
            "         0.01791364,  0.01826443,  0.01647424,  0.01456192],\n",
            "       [-0.04354285,  0.00231309, -0.05782565, -0.06885075,  0.06269525,\n",
            "         0.00953377, -0.00520797,  0.04335412, -0.05354432,  0.05628053,\n",
            "        -0.01530364,  0.08566492, -0.04738481,  0.05396061, -0.02735111,\n",
            "        -0.07215125,  0.02324379, -0.06374966,  0.0071034 , -0.0411115 ,\n",
            "         0.01292666,  0.0391437 , -0.11179416,  0.0581319 , -0.05199806,\n",
            "        -0.04158363,  0.00846227,  0.04897686,  0.04304894, -0.01232419,\n",
            "        -0.02477688,  0.03931331, -0.05045018, -0.00521932,  0.0382753 ,\n",
            "        -0.01386527, -0.02185732, -0.07733958, -0.02674791, -0.01804563,\n",
            "        -0.08182019, -0.03281076, -0.02212935,  0.00334867,  0.0422879 ,\n",
            "         0.01979597, -0.02254249, -0.03988465, -0.00242308, -0.06728536,\n",
            "        -0.12252574, -0.04563113, -0.02388089,  0.01688368, -0.02055874,\n",
            "        -0.02713617, -0.11232544, -0.01705273, -0.09858712, -0.00862401,\n",
            "        -0.08495405,  0.08122294,  0.09517285,  0.06311381],\n",
            "       [ 0.01678985,  0.0134676 ,  0.01308252,  0.01173128,  0.01930107,\n",
            "         0.01647961,  0.01189883,  0.01118532,  0.01568613,  0.01207564,\n",
            "         0.01908053,  0.01714158,  0.02073699,  0.01901066,  0.01722488,\n",
            "         0.01478281,  0.0130212 ,  0.01155848,  0.01616048,  0.01727116,\n",
            "         0.01544937,  0.02041293,  0.01262323,  0.01555144,  0.01636982,\n",
            "         0.01815724,  0.01668097,  0.01351757,  0.01871033,  0.01694596,\n",
            "         0.01849473,  0.0179017 ,  0.01379323,  0.01529346,  0.01787536,\n",
            "         0.01787529,  0.01243789,  0.01079949,  0.01458409,  0.01796604,\n",
            "         0.01068616,  0.0156874 ,  0.01379622,  0.01282271,  0.01388022,\n",
            "         0.01832657,  0.01688085,  0.01211513,  0.01188004,  0.01680652,\n",
            "         0.01428918,  0.01693748,  0.01432636,  0.01225146,  0.01939982,\n",
            "         0.01724773,  0.0175936 ,  0.01591861,  0.01400391,  0.01375548,\n",
            "         0.01766979,  0.01802045,  0.01625401,  0.01436937],\n",
            "       [-0.02410883,  0.00779018, -0.00475522, -0.01179791, -0.01866656,\n",
            "        -0.01294113, -0.00131282, -0.00191195, -0.01736764,  0.00546342,\n",
            "         0.00109475,  0.01172325, -0.00616356, -0.00958062, -0.01437369,\n",
            "        -0.03107931, -0.00623678,  0.00886052, -0.00998897, -0.01877333,\n",
            "        -0.0065113 , -0.01515977, -0.01144789, -0.04189763, -0.03868839,\n",
            "        -0.01695108,  0.00060679,  0.01135344, -0.02158884, -0.03584323,\n",
            "        -0.0325137 , -0.01368545,  0.01537566, -0.02420953, -0.00498023,\n",
            "         0.00092329, -0.01452353, -0.03699941, -0.02209414, -0.0038532 ,\n",
            "        -0.00405613, -0.01709232, -0.01367406,  0.01624618,  0.0030351 ,\n",
            "        -0.00684202, -0.01024097,  0.01255891,  0.01877409, -0.01146167,\n",
            "        -0.04268744, -0.00678457, -0.0061634 , -0.00509807, -0.02955556,\n",
            "        -0.02496933, -0.01919356, -0.011011  , -0.00629187,  0.00341526,\n",
            "        -0.03516602, -0.01930174,  0.00381887,  0.0136335 ],\n",
            "       [ 0.01678147,  0.01344186,  0.01307896,  0.01173257,  0.01925589,\n",
            "         0.01645044,  0.01187682,  0.01115413,  0.01567919,  0.0120377 ,\n",
            "         0.01905577,  0.01708882,  0.02072145,  0.01896549,  0.01720995,\n",
            "         0.01478085,  0.0129904 ,  0.01155328,  0.01613373,  0.01725927,\n",
            "         0.01542106,  0.02037234,  0.0126362 ,  0.01551523,  0.01636372,\n",
            "         0.01814427,  0.01665314,  0.01347764,  0.0186722 ,  0.01692911,\n",
            "         0.01847712,  0.01786226,  0.01377866,  0.01527591,  0.01783695,\n",
            "         0.01785089,  0.01242523,  0.01081006,  0.0145733 ,  0.01794358,\n",
            "         0.01068923,  0.01567685,  0.01378043,  0.01279739,  0.0138424 ,\n",
            "         0.01829373,  0.01686017,  0.01210348,  0.01185664,  0.01679865,\n",
            "         0.01430754,  0.01692582,  0.01431109,  0.01222569,  0.01938085,\n",
            "         0.01723235,  0.0175994 ,  0.01590118,  0.01400834,  0.0137364 ,\n",
            "         0.01767081,  0.0179697 ,  0.0162008 ,  0.01432282],\n",
            "       [-0.04321455,  0.01175077, -0.02440752,  0.00081827, -0.00779208,\n",
            "         0.01162067,  0.03727396,  0.00277854, -0.02350749,  0.00729517,\n",
            "        -0.03096122, -0.00933407, -0.04867279, -0.00049052, -0.0352766 ,\n",
            "         0.00869394,  0.04006733,  0.01333432, -0.00287374, -0.02818046,\n",
            "        -0.00835254, -0.01788646, -0.02072323,  0.0020683 , -0.01279525,\n",
            "        -0.03077572, -0.02618606,  0.01373834, -0.01622145, -0.02457117,\n",
            "        -0.0159112 ,  0.01203355,  0.01531884, -0.02938475, -0.01473424,\n",
            "        -0.01821286, -0.00013513, -0.01823747, -0.02935507, -0.01808877,\n",
            "         0.01312622, -0.03434924, -0.00217682, -0.00477156,  0.02215242,\n",
            "        -0.01837404,  0.00262648,  0.00096995,  0.00371852, -0.00401444,\n",
            "        -0.02225479, -0.02902921, -0.01575527,  0.01082426, -0.03495892,\n",
            "        -0.02231315, -0.01517116, -0.03044845, -0.01051297, -0.01808527,\n",
            "        -0.0195035 ,  0.01063203, -0.00683242,  0.02236755]])]\n",
            "del b [array([[0.37629587]]), array([-5.38550463e-03,  1.41866356e-03, -1.92791489e-03, -6.87262978e-03,\n",
            "       -8.15621496e-04,  2.00633207e-03,  1.99132325e-03, -3.14942899e-03,\n",
            "        3.32977159e-03, -2.77780728e-03,  4.58407121e-03,  5.67662776e-05,\n",
            "        8.59945634e-05, -8.78833614e-06,  1.47628383e-02, -2.42812222e-03,\n",
            "       -1.46357835e-04,  8.96295004e-03, -9.59838515e-03,  4.58585499e-03,\n",
            "        2.96091783e-03, -2.62622687e-03,  2.05134207e-03,  3.37927710e-03,\n",
            "       -1.41940607e-04, -5.00301988e-03,  2.55237553e-03, -1.98994245e-03,\n",
            "        5.07090208e-03,  2.63235610e-03,  7.49942777e-04, -5.18008320e-04,\n",
            "        2.36071810e-04, -4.02540493e-03, -3.16272127e-04,  2.63411055e-03,\n",
            "       -3.97573797e-03,  7.86830001e-03, -4.73148626e-04, -7.62704332e-04,\n",
            "        8.44347728e-03,  1.23109553e-03,  8.37645717e-04,  9.32188038e-04,\n",
            "        5.81264152e-03,  1.67018543e-03,  1.73283216e-03, -6.16341503e-03,\n",
            "        6.11923695e-03, -1.38686378e-04, -5.56236233e-04,  3.56122394e-03,\n",
            "        2.28869062e-03,  4.17968457e-03,  4.19118214e-03, -1.29788863e-03,\n",
            "        5.21201698e-03, -2.20732792e-03, -7.39650142e-04, -1.32035051e-04,\n",
            "        1.32739235e-04, -8.72232263e-04, -3.38661705e-03, -5.76017367e-04]), array([-3.68721767e-03, -3.35195462e-03, -4.40645345e-03, -5.29955482e-03,\n",
            "        5.84283852e-03,  2.52390185e-04, -8.19497221e-03, -5.24754367e-03,\n",
            "       -1.88792367e-03, -5.83318558e-03,  1.14820903e-03,  7.72930738e-03,\n",
            "        9.77260833e-03, -5.53336631e-04,  6.32146317e-05, -3.46389544e-03,\n",
            "       -1.33382159e-03, -6.69926745e-03, -2.39784180e-03, -2.42863338e-03,\n",
            "       -5.10897382e-04,  1.15745173e-03, -5.76145457e-03, -3.47711325e-03,\n",
            "       -3.87245694e-03, -1.38545725e-03, -2.44635356e-03, -2.55790223e-03,\n",
            "        1.95949082e-03, -5.12873093e-03, -3.81679694e-03, -1.80860625e-03,\n",
            "       -6.68935210e-03, -1.25349044e-03, -2.53720836e-03, -3.08872671e-03,\n",
            "       -1.92223581e-03, -3.74715866e-03, -4.09423413e-03, -2.35798948e-04,\n",
            "       -9.65341783e-03, -5.27300157e-03, -3.71757454e-03, -1.24685299e-03,\n",
            "       -4.04442325e-03,  1.11801001e-03, -4.73744578e-03, -5.25027404e-03,\n",
            "       -5.19591646e-03, -2.81585970e-03, -4.06301462e-03,  3.34180095e-03,\n",
            "       -3.61166847e-03,  1.05871593e-04, -2.18504646e-03, -3.33365127e-03,\n",
            "       -1.35009312e-03, -3.26436076e-03, -5.16295189e-03, -2.91160825e-03,\n",
            "       -2.63968559e-03,  4.07621667e-03,  2.83368388e-03,  7.53715588e-04]), array([-0.00716158,  0.02989922,  0.00222312, -0.01791422,  0.02951065,\n",
            "       -0.04082629,  0.02911353, -0.02763799,  0.02908262, -0.02628907])]\n",
            "type of weight  <class 'numpy.ndarray'>\n",
            "type of bias  <class 'numpy.ndarray'>\n",
            "Completed epoch : 100 \t Error: 1.6227936679862274\n",
            "Completed epoch : 101 \t Error: 1.6209832433833526\n",
            "Completed epoch : 102 \t Error: 1.6191411126094235\n",
            "Completed epoch : 103 \t Error: 1.6172663776254073\n",
            "Completed epoch : 104 \t Error: 1.6153581253346794\n",
            "Completed epoch : 105 \t Error: 1.6134154272437944\n",
            "Completed epoch : 106 \t Error: 1.611437339150084\n",
            "Completed epoch : 107 \t Error: 1.6094229008578995\n",
            "Completed epoch : 108 \t Error: 1.6073711359255303\n",
            "Completed epoch : 109 \t Error: 1.6052810514450382\n",
            "Completed epoch : 110 \t Error: 1.6031516378574548\n",
            "Completed epoch : 111 \t Error: 1.6009818688060158\n",
            "Completed epoch : 112 \t Error: 1.5987707010303338\n",
            "Completed epoch : 113 \t Error: 1.5965170743046333\n",
            "Completed epoch : 114 \t Error: 1.5942199114234137\n",
            "Completed epoch : 115 \t Error: 1.5918781182381585\n",
            "Completed epoch : 116 \t Error: 1.5894905837489322\n",
            "Completed epoch : 117 \t Error: 1.587056180254977\n",
            "Completed epoch : 118 \t Error: 1.5845737635686665\n",
            "Completed epoch : 119 \t Error: 1.582042173297425\n",
            "Completed epoch : 120 \t Error: 1.5794602331984797\n",
            "Completed epoch : 121 \t Error: 1.5768267516115666\n",
            "Completed epoch : 122 \t Error: 1.5741405219749471\n",
            "Completed epoch : 123 \t Error: 1.5714003234303637\n",
            "Completed epoch : 124 \t Error: 1.5686049215227524\n",
            "Completed epoch : 125 \t Error: 1.565753069000797\n",
            "Completed epoch : 126 \t Error: 1.5628435067245827\n",
            "Completed epoch : 127 \t Error: 1.5598749646868084\n",
            "Completed epoch : 128 \t Error: 1.5568461631541652\n",
            "Completed epoch : 129 \t Error: 1.5537558139356378\n",
            "Completed epoch : 130 \t Error: 1.5506026217845619\n",
            "Completed epoch : 131 \t Error: 1.5473852859413353\n",
            "Completed epoch : 132 \t Error: 1.5441025018236871\n",
            "Completed epoch : 133 \t Error: 1.5407529628713594\n",
            "Completed epoch : 134 \t Error: 1.5373353625519344\n",
            "Completed epoch : 135 \t Error: 1.533848396534373\n",
            "Completed epoch : 136 \t Error: 1.5302907650365551\n",
            "Completed epoch : 137 \t Error: 1.526661175352761\n",
            "Completed epoch : 138 \t Error: 1.522958344566583\n",
            "Completed epoch : 139 \t Error: 1.5191810024541992\n",
            "Completed epoch : 140 \t Error: 1.5153278945822612\n",
            "Completed epoch : 141 \t Error: 1.51139778560384\n",
            "Completed epoch : 142 \t Error: 1.5073894627549396\n",
            "Completed epoch : 143 \t Error: 1.5033017395529957\n",
            "Completed epoch : 144 \t Error: 1.499133459697538\n",
            "Completed epoch : 145 \t Error: 1.4948835011717976\n",
            "Completed epoch : 146 \t Error: 1.4905507805424618\n",
            "Completed epoch : 147 \t Error: 1.4861342574530565\n",
            "Completed epoch : 148 \t Error: 1.4816329393045207\n",
            "Completed epoch : 149 \t Error: 1.4770458861144475\n",
            "Completed epoch : 150 \t Error: 1.4723722155442371\n",
            "Completed epoch : 151 \t Error: 1.4676111080809693\n",
            "Completed epoch : 152 \t Error: 1.4627618123582677\n",
            "Completed epoch : 153 \t Error: 1.4578236505977133\n",
            "Completed epoch : 154 \t Error: 1.4527960241495426\n",
            "Completed epoch : 155 \t Error: 1.4476784191084744\n",
            "Completed epoch : 156 \t Error: 1.4424704119775111\n",
            "Completed epoch : 157 \t Error: 1.4371716753495645\n",
            "Completed epoch : 158 \t Error: 1.431781983573749\n",
            "Completed epoch : 159 \t Error: 1.4263012183702397\n",
            "Completed epoch : 160 \t Error: 1.4207293743547529\n",
            "Completed epoch : 161 \t Error: 1.415066564430995\n",
            "Completed epoch : 162 \t Error: 1.4093130250069847\n",
            "Completed epoch : 163 \t Error: 1.4034691209889303\n",
            "Completed epoch : 164 \t Error: 1.397535350504505\n",
            "Completed epoch : 165 \t Error: 1.391512349305907\n",
            "Completed epoch : 166 \t Error: 1.3854008948021472\n",
            "Completed epoch : 167 \t Error: 1.3792019096695278\n",
            "Completed epoch : 168 \t Error: 1.372916464989506\n",
            "Completed epoch : 169 \t Error: 1.3665457828639134\n",
            "Completed epoch : 170 \t Error: 1.360091238459052\n",
            "Completed epoch : 171 \t Error: 1.353554361432469\n",
            "Completed epoch : 172 \t Error: 1.3469368366992385\n",
            "Completed epoch : 173 \t Error: 1.3402405044984256\n",
            "Completed epoch : 174 \t Error: 1.3334673597250137\n",
            "Completed epoch : 175 \t Error: 1.3266195504979654\n",
            "Completed epoch : 176 \t Error: 1.319699375941185\n",
            "Completed epoch : 177 \t Error: 1.3127092831609664\n",
            "Completed epoch : 178 \t Error: 1.3056518634108705\n",
            "Completed epoch : 179 \t Error: 1.2985298474429199\n",
            "Completed epoch : 180 \t Error: 1.2913461000522755\n",
            "Completed epoch : 181 \t Error: 1.2841036138311688\n",
            "Completed epoch : 182 \t Error: 1.276805502156598\n",
            "Completed epoch : 183 \t Error: 1.2694549914449977\n",
            "Completed epoch : 184 \t Error: 1.2620554127156816\n",
            "Completed epoch : 185 \t Error: 1.2546101925130697\n",
            "Completed epoch : 186 \t Error: 1.2471228432454866\n",
            "Completed epoch : 187 \t Error: 1.23959695300543\n",
            "Completed epoch : 188 \t Error: 1.2320361749425615\n",
            "Completed epoch : 189 \t Error: 1.224444216266112\n",
            "Completed epoch : 190 \t Error: 1.216824826957806\n",
            "Completed epoch : 191 \t Error: 1.2091817882797495\n",
            "Completed epoch : 192 \t Error: 1.2015189011638365\n",
            "Completed epoch : 193 \t Error: 1.1938399745701886\n",
            "Completed epoch : 194 \t Error: 1.186148813901823\n",
            "Completed epoch : 195 \t Error: 1.1784492095612593\n",
            "Completed epoch : 196 \t Error: 1.1707449257320832\n",
            "Completed epoch : 197 \t Error: 1.1630396894647244\n",
            "Completed epoch : 198 \t Error: 1.1553371801409242\n",
            "Completed epoch : 199 \t Error: 1.14764101938567\n",
            "200 th iteration\n",
            "del w [array([[0.19941967]]), array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "         1.35671666e-03,  0.00000000e+00,  0.00000000e+00],\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "        -1.34000054e-03,  0.00000000e+00,  0.00000000e+00],\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "        -2.47881472e-04,  0.00000000e+00,  0.00000000e+00],\n",
            "       ...,\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "         3.95191118e-05,  0.00000000e+00,  0.00000000e+00],\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "         8.82969911e-04,  0.00000000e+00,  0.00000000e+00],\n",
            "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
            "         4.62398255e-04,  0.00000000e+00,  0.00000000e+00]]), array([[ 0.00975091,  0.02353716, -0.02934123, ..., -0.02078994,\n",
            "        -0.03324151, -0.03479824],\n",
            "       [-0.01326408,  0.00274507,  0.01747889, ...,  0.01599407,\n",
            "         0.00934972,  0.01911941],\n",
            "       [-0.01501108,  0.02644911, -0.00455748, ..., -0.00253469,\n",
            "        -0.02514073, -0.01492623],\n",
            "       ...,\n",
            "       [-0.01851211, -0.0100829 ,  0.04673751, ...,  0.03134011,\n",
            "         0.03771636,  0.04411505],\n",
            "       [ 0.00435252, -0.02672573,  0.04226198, ...,  0.03789822,\n",
            "         0.04738615,  0.05259493],\n",
            "       [-0.03070287,  0.00629342,  0.04671308, ...,  0.03734436,\n",
            "         0.02580677,  0.04529256]]), array([[ 0.15691281, -0.09488824, -0.01540676, -0.04087531, -0.02382212,\n",
            "        -0.18310576, -0.23415621, -0.18091794,  0.10817788, -0.23870802,\n",
            "         0.11316611, -0.0332213 ,  0.2459591 , -0.06702484,  0.23144512,\n",
            "        -0.12391248, -0.14210406, -0.13519637,  0.00811738,  0.15233724,\n",
            "        -0.0908108 ,  0.03049797,  0.04256251, -0.15589157,  0.0658935 ,\n",
            "         0.1684068 ,  0.01359729, -0.12788949,  0.05030936,  0.01894883,\n",
            "        -0.00867076, -0.09327126, -0.21187017,  0.15303377, -0.02675377,\n",
            "         0.02512107, -0.03572414,  0.13055782,  0.09846751,  0.1046454 ,\n",
            "        -0.08810297,  0.1199442 , -0.07086484, -0.12116106, -0.17090818,\n",
            "         0.09400903,  0.03120078, -0.039487  , -0.08083674,  0.02925895,\n",
            "         0.12520998,  0.19346616, -0.02767242, -0.09254417,  0.1198138 ,\n",
            "         0.1237327 ,  0.12676   , -0.00545325, -0.01423943,  0.0944574 ,\n",
            "         0.15623828, -0.22013138, -0.13788361, -0.26065248],\n",
            "       [ 0.00816296,  0.00669239,  0.00660878,  0.00602329,  0.00916116,\n",
            "         0.00727976,  0.00589098,  0.00610627,  0.00806077,  0.00623165,\n",
            "         0.00951423,  0.00820612,  0.00956778,  0.00938689,  0.00884769,\n",
            "         0.00697422,  0.00660202,  0.00579234,  0.00842768,  0.00877956,\n",
            "         0.00758375,  0.01019791,  0.00644628,  0.00754071,  0.00794416,\n",
            "         0.00914949,  0.00863267,  0.00701036,  0.00930498,  0.0086939 ,\n",
            "         0.00911223,  0.00874677,  0.00651167,  0.00834059,  0.00901856,\n",
            "         0.00936236,  0.00610594,  0.00617506,  0.00790844,  0.00907214,\n",
            "         0.00565876,  0.00800575,  0.00666706,  0.0064709 ,  0.00687516,\n",
            "         0.00911794,  0.00837541,  0.00604368,  0.00585981,  0.00779471,\n",
            "         0.00705111,  0.00867813,  0.00697868,  0.00607933,  0.01004541,\n",
            "         0.00913298,  0.00798506,  0.00793916,  0.00656714,  0.00755847,\n",
            "         0.00863406,  0.00799489,  0.0079211 ,  0.006613  ],\n",
            "       [ 0.03193464,  0.01797311,  0.11628916,  0.14588695, -0.15004083,\n",
            "         0.10971914,  0.1426095 ,  0.02430716, -0.00441323,  0.05906241,\n",
            "        -0.11217168, -0.22961056, -0.1337841 , -0.09451189, -0.16749121,\n",
            "         0.22272568, -0.01789526,  0.17544876, -0.04793873, -0.03909901,\n",
            "        -0.0282246 , -0.11833861,  0.20411894,  0.04394828,  0.10936564,\n",
            "        -0.05856976, -0.0944869 , -0.0723442 , -0.15554653,  0.01523274,\n",
            "         0.06874105, -0.03970108,  0.20538772, -0.11373167, -0.08076328,\n",
            "        -0.04708589,  0.05365363,  0.07313406, -0.021056  , -0.12720165,\n",
            "         0.19833726, -0.02684   ,  0.09870514,  0.00987923, -0.00733902,\n",
            "        -0.16265391, -0.01007209,  0.0662953 ,  0.0418739 ,  0.1223226 ,\n",
            "         0.19651227, -0.1046383 ,  0.06401831,  0.04808983, -0.07125002,\n",
            "        -0.0705889 ,  0.11152808,  0.04838372,  0.19983288, -0.10997087,\n",
            "         0.02723182, -0.00361098, -0.12421438,  0.03106204],\n",
            "       [ 0.04693842, -0.0548998 ,  0.00448125, -0.02752894, -0.03465318,\n",
            "        -0.0833859 , -0.10993976, -0.07776187,  0.04185824, -0.108407  ,\n",
            "         0.02968797, -0.04091881,  0.08025505, -0.04870309,  0.06366114,\n",
            "        -0.05022147, -0.07457547, -0.05781322, -0.01678746,  0.04045481,\n",
            "        -0.04973369, -0.01012897,  0.02030003, -0.0833646 ,  0.02007129,\n",
            "         0.04985683, -0.01250559, -0.06746213, -0.00242651, -0.00075042,\n",
            "        -0.01368701, -0.0647802 , -0.08651126,  0.04817268, -0.02796579,\n",
            "        -0.01304128, -0.02914904,  0.0446216 ,  0.03383503,  0.02615114,\n",
            "        -0.03527632,  0.02732663, -0.0361488 , -0.05357285, -0.09409749,\n",
            "         0.01877955, -0.01201619, -0.02438504, -0.04388769, -0.00109762,\n",
            "         0.05727603,  0.07295593, -0.01869175, -0.05644074,  0.03962458,\n",
            "         0.04119709,  0.05055544, -0.00912316,  0.0008151 ,  0.01582197,\n",
            "         0.05359449, -0.10211638, -0.0674572 , -0.11699256],\n",
            "       [ 0.00775227,  0.00638863,  0.00627564,  0.00571868,  0.00876932,\n",
            "         0.00694881,  0.00562254,  0.00584483,  0.00766659,  0.00596689,\n",
            "         0.00906932,  0.00787103,  0.00910525,  0.00897857,  0.00843117,\n",
            "         0.00662644,  0.00631854,  0.00550397,  0.00804145,  0.00835391,\n",
            "         0.00724677,  0.00974161,  0.00609567,  0.0072145 ,  0.00754485,\n",
            "         0.00870628,  0.00824323,  0.00671347,  0.00889498,  0.00828609,\n",
            "         0.00867933,  0.00836441,  0.00619382,  0.00795121,  0.00861772,\n",
            "         0.00892827,  0.00581781,  0.00585518,  0.00752953,  0.00865211,\n",
            "         0.00536481,  0.00761914,  0.00634659,  0.00617994,  0.00658315,\n",
            "         0.00870827,  0.00798108,  0.00574792,  0.00558633,  0.00740062,\n",
            "         0.00666669,  0.00825748,  0.0066425 ,  0.00580176,  0.009573  ,\n",
            "         0.00870052,  0.00756804,  0.00755926,  0.00621831,  0.00720927,\n",
            "         0.00820175,  0.00766069,  0.00759581,  0.00633673],\n",
            "       [-0.12323035,  0.04090756, -0.09106516, -0.10793423,  0.18007575,\n",
            "         0.065347  ,  0.02383374,  0.14271822, -0.08396999,  0.16206536,\n",
            "        -0.01178095,  0.22991485, -0.09188482,  0.15141114, -0.03502986,\n",
            "        -0.09257386,  0.09752307, -0.09041139,  0.03543956, -0.07831038,\n",
            "         0.08893948,  0.11500026, -0.22709668,  0.17690187, -0.11867038,\n",
            "        -0.08577509,  0.07392155,  0.14121489,  0.1258685 ,  0.02676731,\n",
            "         0.00064103,  0.13354301, -0.06865881,  0.01320334,  0.11551935,\n",
            "         0.01801377, -0.01210033, -0.13870701, -0.01860067, -0.00659768,\n",
            "        -0.15947757, -0.05036385, -0.03644129,  0.06283123,  0.14177696,\n",
            "         0.07179286, -0.04035606, -0.08119121, -0.00296748, -0.15597161,\n",
            "        -0.23973411, -0.09546251, -0.03996873,  0.04583319,  0.00115302,\n",
            "        -0.02679859, -0.22391555, -0.01544363, -0.20360197,  0.01195905,\n",
            "        -0.15102372,  0.21842697,  0.23749379,  0.17354956],\n",
            "       [ 0.00795835,  0.00660468,  0.00645954,  0.00588875,  0.00906411,\n",
            "         0.00719087,  0.00582942,  0.00606209,  0.00788101,  0.00619702,\n",
            "         0.00933856,  0.00814856,  0.00935053,  0.00928247,  0.00866395,\n",
            "         0.00683275,  0.00654457,  0.00568185,  0.00829483,  0.00858643,\n",
            "         0.00749389,  0.01005223,  0.0062524 ,  0.00747051,  0.00775384,\n",
            "         0.00894754,  0.00850724,  0.00695597,  0.009179  ,  0.00853917,\n",
            "         0.00894461,  0.00864953,  0.00640531,  0.00817959,  0.00890076,\n",
            "         0.00920593,  0.00600044,  0.00600277,  0.00774599,  0.00891083,\n",
            "         0.00552495,  0.00783525,  0.00654738,  0.00639503,  0.00682506,\n",
            "         0.00897672,  0.00822265,  0.00592555,  0.00577123,  0.00760973,\n",
            "         0.00682553,  0.00848215,  0.00684711,  0.00599767,  0.00985331,\n",
            "         0.00895188,  0.00776163,  0.00779044,  0.00638964,  0.00742589,\n",
            "         0.00841973,  0.00794582,  0.00787421,  0.00658451],\n",
            "       [-0.04443562,  0.02623705,  0.00899679,  0.00585572, -0.03458312,\n",
            "        -0.00276593,  0.04242833,  0.0148116 , -0.03336285,  0.02931703,\n",
            "         0.00121765,  0.01627816, -0.02774667, -0.01377397, -0.04599709,\n",
            "        -0.02151184,  0.00927283,  0.04118783, -0.01077697, -0.04200682,\n",
            "         0.0214918 , -0.03113288, -0.00539703, -0.06131691, -0.05929836,\n",
            "        -0.03776428,  0.00912193,  0.03821679, -0.03646814, -0.05869367,\n",
            "        -0.05817662, -0.02608969,  0.06779635, -0.05607063, -0.01278398,\n",
            "        -0.00036029, -0.01989929, -0.0600666 , -0.05162211, -0.00377603,\n",
            "         0.02626869, -0.02886413,  0.00285569,  0.05177626,  0.01661953,\n",
            "        -0.02622843, -0.01660248,  0.04473926,  0.03908381, -0.01014014,\n",
            "        -0.07183954, -0.01998913,  0.00409403,  0.00522961, -0.06007437,\n",
            "        -0.04647629, -0.03201499, -0.00966408,  0.01718269, -0.00083832,\n",
            "        -0.05789093, -0.01370759,  0.01491073,  0.04888188],\n",
            "       [ 0.00807679,  0.00648259,  0.0064945 ,  0.00591239,  0.00886028,\n",
            "         0.00702593,  0.00566029,  0.00584904,  0.00794222,  0.00594569,\n",
            "         0.00932599,  0.00789854,  0.00945374,  0.00907761,  0.00871981,\n",
            "         0.00681288,  0.00635127,  0.00564722,  0.00821402,  0.00865181,\n",
            "         0.0073357 ,  0.00992053,  0.00640766,  0.00724975,  0.00783341,\n",
            "         0.00902022,  0.00840004,  0.00673815,  0.009047  ,  0.00849344,\n",
            "         0.00890381,  0.00845203,  0.00631535,  0.00819031,  0.00874983,\n",
            "         0.00913911,  0.00595442,  0.00613372,  0.00776923,  0.00888614,\n",
            "         0.00555932,  0.00787707,  0.0065023 ,  0.00625176,  0.00659372,\n",
            "         0.0088986 ,  0.00819516,  0.00591538,  0.00569258,  0.00768163,\n",
            "         0.00703692,  0.0085705 ,  0.00682303,  0.0058871 ,  0.00985096,\n",
            "         0.00896891,  0.00793047,  0.00776298,  0.00649382,  0.00740056,\n",
            "         0.00854159,  0.00764939,  0.00759312,  0.00630042],\n",
            "       [-0.10007028,  0.03850201, -0.04913374,  0.00105271,  0.02716862,\n",
            "         0.06574608,  0.11222117,  0.0529806 , -0.05984063,  0.07232897,\n",
            "        -0.05736721,  0.02543341, -0.11027585,  0.03587711, -0.08125073,\n",
            "         0.03824768,  0.1019625 ,  0.04415902, -0.00103177, -0.06774756,\n",
            "         0.02867769, -0.02581004, -0.05968978,  0.05024746, -0.04843795,\n",
            "        -0.07197802, -0.02343144,  0.0608462 , -0.01816264, -0.03551738,\n",
            "        -0.02448767,  0.05608649,  0.06843003, -0.07726919, -0.00253939,\n",
            "        -0.01928304,  0.01934056, -0.07370659, -0.07197695, -0.02874239,\n",
            "         0.03614308, -0.07254006,  0.01583076,  0.02494955,  0.08707111,\n",
            "        -0.03140062,  0.01507173,  0.01039615,  0.02382425, -0.01485887,\n",
            "        -0.09500487, -0.0803204 , -0.00907078,  0.0260664 , -0.06858968,\n",
            "        -0.0568203 , -0.06415818, -0.03975144, -0.02565817, -0.04102343,\n",
            "        -0.06194706,  0.08988858,  0.04616642,  0.0983169 ]])]\n",
            "del b [array([[0.12829761]]), array([-1.71764793e-02,  1.19666686e-02, -7.73910220e-03, -1.65715275e-02,\n",
            "       -8.81450771e-03, -1.46236951e-03, -5.38620422e-04, -1.61480106e-02,\n",
            "        1.33404002e-02, -1.54039407e-02,  1.73008573e-02, -1.06166983e-03,\n",
            "       -1.23937477e-03, -2.00474517e-03,  2.80326986e-02, -1.13304906e-02,\n",
            "       -3.07284900e-03,  2.51600169e-02, -1.87621567e-02,  1.58778871e-02,\n",
            "        1.34771346e-02, -1.40670680e-02,  2.98446798e-03,  1.54967879e-02,\n",
            "       -8.71454431e-04, -2.07200226e-02,  1.10503928e-02, -4.70668935e-03,\n",
            "        1.80766400e-02,  1.43611384e-02, -8.59729204e-04,  1.14026050e-03,\n",
            "        2.77234821e-03, -2.11575906e-02, -4.03278767e-03,  1.69130080e-02,\n",
            "       -7.65135719e-03,  1.18286930e-02, -6.00984604e-03, -6.51829700e-03,\n",
            "        1.97388831e-02,  4.90625024e-03,  3.03223407e-03,  2.07458632e-03,\n",
            "        8.52108731e-03,  9.51067589e-03,  1.01037034e-02, -1.94697607e-02,\n",
            "        1.25119973e-02, -1.03894426e-02, -1.68036690e-03,  1.13827316e-02,\n",
            "        9.26584262e-03,  1.26990713e-02,  1.02861240e-02, -9.31110542e-03,\n",
            "        1.84449745e-02, -1.13908621e-02, -3.58356510e-05,  2.74775122e-03,\n",
            "       -3.13278182e-03, -5.42250472e-03, -1.75319404e-02, -9.21191845e-03]), array([ 0.00259396, -0.00148656, -0.00697027, -0.01314102,  0.02077509,\n",
            "        0.00684466, -0.02118197, -0.01162846, -0.00111257, -0.01160562,\n",
            "        0.01145519,  0.02179135,  0.03059415,  0.00958594,  0.01552606,\n",
            "       -0.01667121, -0.00528311, -0.02257283, -0.00028569,  0.00241169,\n",
            "        0.00436351,  0.01512112, -0.01529248,  0.00032863,  0.00019536,\n",
            "        0.008429  ,  0.00380351, -0.00184038,  0.0176145 , -0.00211895,\n",
            "        0.00022091,  0.00687653, -0.01756671,  0.0030501 ,  0.00390396,\n",
            "       -0.00070086, -0.0020959 , -0.01340143, -0.00364186,  0.01126688,\n",
            "       -0.03126766, -0.0021057 , -0.00290536, -0.0007467 , -0.00322589,\n",
            "        0.01640852, -0.00107537, -0.00647453, -0.00399203,  0.0033944 ,\n",
            "       -0.00564817,  0.01182171, -0.00103292, -0.00223024,  0.0080662 ,\n",
            "        0.00227574,  0.01375066, -0.00207526, -0.01230144, -0.0004874 ,\n",
            "        0.00797106,  0.01608658,  0.00418955,  0.00321151]), array([ 0.03351761,  0.01465317,  0.00271389, -0.00996755,  0.01396282,\n",
            "       -0.01348788,  0.0143894 , -0.03377552,  0.0143249 , -0.03633084])]\n",
            "type of weight  <class 'numpy.ndarray'>\n",
            "type of bias  <class 'numpy.ndarray'>\n",
            "Completed epoch : 200 \t Error: 1.139954761488949\n",
            "Completed epoch : 201 \t Error: 1.1322818843925602\n",
            "Completed epoch : 202 \t Error: 1.124625781289675\n",
            "Completed epoch : 203 \t Error: 1.1169897528769155\n",
            "Completed epoch : 204 \t Error: 1.1093770002906649\n",
            "Completed epoch : 205 \t Error: 1.1017906187511535\n",
            "Completed epoch : 206 \t Error: 1.0942335919299149\n",
            "Completed epoch : 207 \t Error: 1.086708787048355\n",
            "Completed epoch : 208 \t Error: 1.0792189507077887\n",
            "Completed epoch : 209 \t Error: 1.071766705444274\n",
            "Completed epoch : 210 \t Error: 1.0643545469951197\n",
            "Completed epoch : 211 \t Error: 1.0569848422580728\n",
            "Completed epoch : 212 \t Error: 1.0496598279189484\n",
            "Completed epoch : 213 \t Error: 1.0423816097189096\n",
            "Completed epoch : 214 \t Error: 1.0351521623287439\n",
            "Completed epoch : 215 \t Error: 1.0279733297942728\n",
            "Completed epoch : 216 \t Error: 1.0208468265145596\n",
            "Completed epoch : 217 \t Error: 1.0137742387126791\n",
            "Completed epoch : 218 \t Error: 1.0067570263576218\n",
            "Completed epoch : 219 \t Error: 0.9997965254952023\n",
            "Completed epoch : 220 \t Error: 0.9928939509457418\n",
            "Completed epoch : 221 \t Error: 0.9860503993266143\n",
            "Completed epoch : 222 \t Error: 0.9792668523585355\n",
            "Completed epoch : 223 \t Error: 0.972544180415605\n",
            "Completed epoch : 224 \t Error: 0.9658831462805646\n",
            "Completed epoch : 225 \t Error: 0.9592844090684446\n",
            "Completed epoch : 226 \t Error: 0.9527485282837109\n",
            "Completed epoch : 227 \t Error: 0.9462759679780899\n",
            "Completed epoch : 228 \t Error: 0.9398671009784578\n",
            "Completed epoch : 229 \t Error: 0.9335222131564626\n",
            "Completed epoch : 230 \t Error: 0.9272415077138396\n",
            "Completed epoch : 231 \t Error: 0.9210251094597339\n",
            "Completed epoch : 232 \t Error: 0.914873069058606\n",
            "Completed epoch : 233 \t Error: 0.9087853672295664\n",
            "Completed epoch : 234 \t Error: 0.9027619188801598\n",
            "Completed epoch : 235 \t Error: 0.8968025771597178\n",
            "Completed epoch : 236 \t Error: 0.8909071374193909\n",
            "Completed epoch : 237 \t Error: 0.8850753410678713\n",
            "Completed epoch : 238 \t Error: 0.8793068793135854\n",
            "Completed epoch : 239 \t Error: 0.8736013967857874\n",
            "Completed epoch : 240 \t Error: 0.8679584950285276\n",
            "Completed epoch : 241 \t Error: 0.8623777358628617\n",
            "Completed epoch : 242 \t Error: 0.8568586446139695\n",
            "Completed epoch : 243 \t Error: 0.8514007132010002\n",
            "Completed epoch : 244 \t Error: 0.8460034030885254\n",
            "Completed epoch : 245 \t Error: 0.8406661480994106\n",
            "Completed epoch : 246 \t Error: 0.8353883570897406\n",
            "Completed epoch : 247 \t Error: 0.830169416487181\n",
            "Completed epoch : 248 \t Error: 0.825008692694771\n",
            "Completed epoch : 249 \t Error: 0.8199055343627037\n",
            "Completed epoch : 250 \t Error: 0.8148592745311065\n",
            "Completed epoch : 251 \t Error: 0.8098692326472182\n",
            "Completed epoch : 252 \t Error: 0.8049347164606916\n",
            "Completed epoch : 253 \t Error: 0.8000550238009818\n",
            "Completed epoch : 254 \t Error: 0.7952294442409995\n",
            "Completed epoch : 255 \t Error: 0.7904572606513426\n",
            "Completed epoch : 256 \t Error: 0.7857377506495167\n",
            "Completed epoch : 257 \t Error: 0.7810701879486225\n",
            "Completed epoch : 258 \t Error: 0.7764538436100062\n",
            "Completed epoch : 259 \t Error: 0.7718879872043529\n",
            "Completed epoch : 260 \t Error: 0.767371887885678\n",
            "Completed epoch : 261 \t Error: 0.7629048153826059\n",
            "Completed epoch : 262 \t Error: 0.7584860409112456\n",
            "Completed epoch : 263 \t Error: 0.7541148380138667\n",
            "Completed epoch : 264 \t Error: 0.7497904833274988\n",
            "Completed epoch : 265 \t Error: 0.7455122572864058\n",
            "Completed epoch : 266 \t Error: 0.7412794447623134\n",
            "Completed epoch : 267 \t Error: 0.7370913356460801\n",
            "Completed epoch : 268 \t Error: 0.7329472253743947\n",
            "Completed epoch : 269 \t Error: 0.728846415404919\n",
            "Completed epoch : 270 \t Error: 0.7247882136431565\n",
            "Completed epoch : 271 \t Error: 0.7207719348241792\n",
            "Completed epoch : 272 \t Error: 0.7167969008521891\n",
            "Completed epoch : 273 \t Error: 0.7128624411007626\n",
            "Completed epoch : 274 \t Error: 0.7089678926764666\n",
            "Completed epoch : 275 \t Error: 0.7051126006484063\n",
            "Completed epoch : 276 \t Error: 0.7012959182461189\n",
            "Completed epoch : 277 \t Error: 0.6975172070281077\n",
            "Completed epoch : 278 \t Error: 0.6937758370231661\n",
            "Completed epoch : 279 \t Error: 0.6900711868465369\n",
            "Completed epoch : 280 \t Error: 0.6864026437928146\n",
            "Completed epoch : 281 \t Error: 0.6827696039073949\n",
            "Completed epoch : 282 \t Error: 0.6791714720381725\n",
            "Completed epoch : 283 \t Error: 0.6756076618690617\n",
            "Completed epoch : 284 \t Error: 0.672077595936845\n",
            "Completed epoch : 285 \t Error: 0.6685807056327332\n",
            "Completed epoch : 286 \t Error: 0.6651164311899482\n",
            "Completed epoch : 287 \t Error: 0.6616842216585538\n",
            "Completed epoch : 288 \t Error: 0.6582835348686655\n",
            "Completed epoch : 289 \t Error: 0.6549138373831135\n",
            "Completed epoch : 290 \t Error: 0.6515746044405482\n",
            "Completed epoch : 291 \t Error: 0.6482653198899125\n",
            "Completed epoch : 292 \t Error: 0.6449854761171526\n",
            "Completed epoch : 293 \t Error: 0.6417345739649568\n",
            "Completed epoch : 294 \t Error: 0.6385121226462841\n",
            "Completed epoch : 295 \t Error: 0.6353176396523631\n",
            "Completed epoch : 296 \t Error: 0.6321506506558181\n",
            "Completed epoch : 297 \t Error: 0.6290106894095152\n",
            "Completed epoch : 298 \t Error: 0.6258972976416859\n",
            "Completed epoch : 299 \t Error: 0.6228100249478425\n",
            "Completed epoch : 300 \t Error: 0.6197484286799659\n",
            "Completed epoch : 301 \t Error: 0.6167120738334045\n",
            "Completed epoch : 302 \t Error: 0.6137005329318956\n",
            "Completed epoch : 303 \t Error: 0.6107133859110874\n",
            "Completed epoch : 304 \t Error: 0.607750220000912\n",
            "Completed epoch : 305 \t Error: 0.6048106296071273\n",
            "Completed epoch : 306 \t Error: 0.6018942161923363\n",
            "Completed epoch : 307 \t Error: 0.5990005881567458\n",
            "Completed epoch : 308 \t Error: 0.5961293607189251\n",
            "Completed epoch : 309 \t Error: 0.5932801557967962\n",
            "Completed epoch : 310 \t Error: 0.5904526018890657\n",
            "Completed epoch : 311 \t Error: 0.5876463339572953\n",
            "Completed epoch : 312 \t Error: 0.5848609933087947\n",
            "Completed epoch : 313 \t Error: 0.5820962274804936\n",
            "Completed epoch : 314 \t Error: 0.579351690123947\n",
            "Completed epoch : 315 \t Error: 0.5766270408916107\n",
            "Completed epoch : 316 \t Error: 0.5739219453245048\n",
            "Completed epoch : 317 \t Error: 0.5712360747413876\n",
            "Completed epoch : 318 \t Error: 0.5685691061295299\n",
            "Completed epoch : 319 \t Error: 0.565920722037189\n",
            "Completed epoch : 320 \t Error: 0.5632906104678601\n",
            "Completed epoch : 321 \t Error: 0.5606784647763785\n",
            "Completed epoch : 322 \t Error: 0.5580839835669398\n",
            "Completed epoch : 323 \t Error: 0.5555068705930866\n",
            "Completed epoch : 324 \t Error: 0.5529468346597246\n",
            "Completed epoch : 325 \t Error: 0.5504035895271958\n",
            "Completed epoch : 326 \t Error: 0.5478768538174561\n",
            "Completed epoch : 327 \t Error: 0.5453663509223817\n",
            "Completed epoch : 328 \t Error: 0.5428718089142295\n",
            "Completed epoch : 329 \t Error: 0.5403929604582738\n",
            "Completed epoch : 330 \t Error: 0.5379295427276306\n",
            "Completed epoch : 331 \t Error: 0.5354812973202779\n",
            "Completed epoch : 332 \t Error: 0.5330479701782831\n",
            "Completed epoch : 333 \t Error: 0.5306293115092295\n",
            "Completed epoch : 334 \t Error: 0.5282250757098497\n",
            "Completed epoch : 335 \t Error: 0.5258350212918487\n",
            "Completed epoch : 336 \t Error: 0.5234589108099158\n",
            "Completed epoch : 337 \t Error: 0.5210965107919087\n",
            "Completed epoch : 338 \t Error: 0.5187475916711904\n",
            "Completed epoch : 339 \t Error: 0.5164119277211038\n",
            "Completed epoch : 340 \t Error: 0.5140892969915626\n",
            "Completed epoch : 341 \t Error: 0.5117794812477344\n",
            "Completed epoch : 342 \t Error: 0.5094822659107818\n",
            "Completed epoch : 343 \t Error: 0.5071974400006459\n",
            "Completed epoch : 344 \t Error: 0.5049247960808304\n",
            "Completed epoch : 345 \t Error: 0.5026641302051559\n",
            "Completed epoch : 346 \t Error: 0.5004152418664553\n",
            "Completed epoch : 347 \t Error: 0.4981779339471638\n",
            "Completed epoch : 348 \t Error: 0.495952012671776\n",
            "Completed epoch : 349 \t Error: 0.4937372875611231\n",
            "Completed epoch : 350 \t Error: 0.4915335713884306\n",
            "Completed epoch : 351 \t Error: 0.48934068013711735\n",
            "Completed epoch : 352 \t Error: 0.487158432960291\n",
            "Completed epoch : 353 \t Error: 0.48498665214189407\n",
            "Completed epoch : 354 \t Error: 0.48282516305945533\n",
            "Completed epoch : 355 \t Error: 0.48067379414840306\n",
            "Completed epoch : 356 \t Error: 0.47853237686789063\n",
            "Completed epoch : 357 \t Error: 0.47640074566808527\n",
            "Completed epoch : 358 \t Error: 0.47427873795887654\n",
            "Completed epoch : 359 \t Error: 0.47216619407994936\n",
            "Completed epoch : 360 \t Error: 0.47006295727217734\n",
            "Completed epoch : 361 \t Error: 0.46796887365028317\n",
            "Completed epoch : 362 \t Error: 0.4658837921767164\n",
            "Completed epoch : 363 \t Error: 0.4638075646367018\n",
            "Completed epoch : 364 \t Error: 0.4617400456144001\n",
            "Completed epoch : 365 \t Error: 0.4596810924701412\n",
            "Completed epoch : 366 \t Error: 0.45763056531866503\n",
            "Completed epoch : 367 \t Error: 0.45558832700833457\n",
            "Completed epoch : 368 \t Error: 0.45355424310125825\n",
            "Completed epoch : 369 \t Error: 0.4515281818542788\n",
            "Completed epoch : 370 \t Error: 0.44951001420077163\n",
            "Completed epoch : 371 \t Error: 0.44749961373321057\n",
            "Completed epoch : 372 \t Error: 0.44549685668644334\n",
            "Completed epoch : 373 \t Error: 0.44350162192163456\n",
            "Completed epoch : 374 \t Error: 0.44151379091081866\n",
            "Completed epoch : 375 \t Error: 0.4395332477220239\n",
            "Completed epoch : 376 \t Error: 0.43755987900491056\n",
            "Completed epoch : 377 \t Error: 0.4355935739768831\n",
            "Completed epoch : 378 \t Error: 0.43363422440962374\n",
            "Completed epoch : 379 \t Error: 0.4316817246160042\n",
            "Completed epoch : 380 \t Error: 0.42973597143732833\n",
            "Completed epoch : 381 \t Error: 0.4277968642308613\n",
            "Completed epoch : 382 \t Error: 0.4258643048576035\n",
            "Completed epoch : 383 \t Error: 0.42393819767026014\n",
            "Completed epoch : 384 \t Error: 0.42201844950136813\n",
            "Completed epoch : 385 \t Error: 0.4201049696515381\n",
            "Completed epoch : 386 \t Error: 0.41819766987776835\n",
            "Completed epoch : 387 \t Error: 0.41629646438179374\n",
            "Completed epoch : 388 \t Error: 0.41440126979842545\n",
            "Completed epoch : 389 \t Error: 0.4125120051838496\n",
            "Completed epoch : 390 \t Error: 0.41062859200384044\n",
            "Completed epoch : 391 \t Error: 0.4087509541218597\n",
            "Completed epoch : 392 \t Error: 0.40687901778699737\n",
            "Completed epoch : 393 \t Error: 0.40501271162172897\n",
            "Completed epoch : 394 \t Error: 0.40315196660944697\n",
            "Completed epoch : 395 \t Error: 0.4012967160817416\n",
            "Completed epoch : 396 \t Error: 0.3994468957053953\n",
            "Completed epoch : 397 \t Error: 0.3976024434690619\n",
            "Completed epoch : 398 \t Error: 0.39576329966960194\n",
            "Completed epoch : 399 \t Error: 0.39392940689804384\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Sigmoid GD Small data{ vertical-output: true}\n",
        "model1 = Classification(_no_of_class=10, \n",
        "                       _hidden_layer=[64, 64], \n",
        "                       _input_layer=784,\n",
        "                       _initialization_method=InitializationMethod.UNIFORM_XAVIER,\n",
        "                       _learning_rate=0.01,\n",
        "                       _activation_fun=ActivationFunction.SIGMOID, \n",
        "                       _optimization_algorithm=OptimizationAlgorithm.GD,\n",
        "                       _max_epoch=400)\n",
        "model1.set_weight_and_bias()\n",
        "\n",
        "model1.fit(x_train[:10], y_train[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h0_GdmG_Jy_l"
      },
      "outputs": [],
      "source": [
        "#@title Sigmoid Momentum Whole data{vertical-output:true}\n",
        "model3 = Classification(_no_of_class=10, \n",
        "                       _hidden_layer=[32, 32], \n",
        "                       _input_layer=784,\n",
        "                       _initialization_method=InitializationMethod.UNIFORM_XAVIER,\n",
        "                       _learning_rate=0.01,\n",
        "                       _activation_fun=ActivationFunction.SIGMOID, \n",
        "                       _optimization_algorithm=OptimizationAlgorithm.MOMENTUM_GD,\n",
        "                       _batch_size = 50,\n",
        "                       _momentum = 0.9,\n",
        "                       _max_epoch=80)\n",
        "\n",
        "model3.set_weight_and_bias()\n",
        "\n",
        "model3.fit(x_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9_QxP5GGghKL"
      },
      "outputs": [],
      "source": [
        "#@title Sigmoid NAG Whole data{vertical-output:true}\n",
        "model4 = Classification(_no_of_class=10, \n",
        "                       _hidden_layer=[32, 32], \n",
        "                       _input_layer=784,\n",
        "                       _initialization_method=InitializationMethod.UNIFORM_XAVIER,\n",
        "                       _learning_rate=0.01,\n",
        "                       _activation_fun=ActivationFunction.SIGMOID, \n",
        "                       _optimization_algorithm=OptimizationAlgorithm.NAG,\n",
        "                       _batch_size = 50,\n",
        "                       _momentum = 0.9,\n",
        "                       _max_epoch=80)\n",
        "\n",
        "model4.set_weight_and_bias()\n",
        "\n",
        "model4.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cFcldgaNpKkX"
      },
      "outputs": [],
      "source": [
        "#@title Sigmoid SGD whole data{ vertical-output: true}\n",
        "model5 = Classification(_no_of_class=10, \n",
        "                       _hidden_layer=[64, 64], \n",
        "                       _input_layer=784,\n",
        "                       _initialization_method=InitializationMethod.UNIFORM_XAVIER,\n",
        "                       _learning_rate=0.01,\n",
        "                       _activation_fun=ActivationFunction.SIGMOID, \n",
        "                       _optimization_algorithm=OptimizationAlgorithm.SGD,\n",
        "                       _max_epoch=10)\n",
        "model5.set_weight_and_bias()\n",
        "\n",
        "model5.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "cTln1aXTz3AW",
        "outputId": "04b77870-b917-4251-b52b-22900e93b924"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-110-bc738ba63d71>:320: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.weight -= new_lr_w * del_w\n",
            "<ipython-input-110-bc738ba63d71>:321: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  self.bias -= new_lr_b * del_b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed epoch : 0 \t Error: 0.9237265999284755\n",
            "Completed epoch : 1 \t Error: 0.7250238375980057\n",
            "Completed epoch : 2 \t Error: 0.6892174484882004\n",
            "Completed epoch : 3 \t Error: 0.6751312273186686\n",
            "Completed epoch : 4 \t Error: 0.6546716767707618\n",
            "Completed epoch : 5 \t Error: 0.6681998486120238\n",
            "Completed epoch : 6 \t Error: 0.6512067302496721\n",
            "Completed epoch : 7 \t Error: 0.6458733169392257\n",
            "Completed epoch : 8 \t Error: 0.6546229436790653\n",
            "Completed epoch : 9 \t Error: 0.6537052775383998\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Sigmoid RMS whole data{ vertical-output: true}\n",
        "model6 = Classification(_no_of_class=10, \n",
        "                       _hidden_layer=[32, 32], \n",
        "                       _input_layer=784,\n",
        "                       _initialization_method=InitializationMethod.UNIFORM_XAVIER,\n",
        "                       _learning_rate=0.1,\n",
        "                       _activation_fun=ActivationFunction.SIGMOID, \n",
        "                       _optimization_algorithm=OptimizationAlgorithm.RMS_PROP,\n",
        "                       _batch_size = 100,\n",
        "                       _momentum = 0.9,\n",
        "                       _max_epoch=10)\n",
        "model6.set_weight_and_bias()\n",
        "\n",
        "model6.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd6H4p546E9I",
        "outputId": "52bbba55-01ef-4176-9aba-48693bfb030f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_test (10000, 784) \t y_test (10000,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8533"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model6.test(x_test,y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "2b7beba6bc4576b587b472b50647070571a61f12f0cc1be023be2a084234b362"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}